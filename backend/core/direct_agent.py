"""
Direct Agent - æ™®é€šæ¨¡å¼ Agent

ä¸ç»è¿‡è§’è‰²æ¶Œç°/Subagent ç¼–æ’ï¼Œç›´æ¥ç”¨å•ä¸ª Agent å“åº”ç”¨æˆ·è¯·æ±‚ã€‚
åŒæ ·å…·å¤‡å®Œæ•´çš„ skills å’Œ memory èƒ½åŠ›ã€‚

è®¾è®¡åŸåˆ™ï¼š
- ç®€å•ç›´æ¥ï¼šä¸€ä¸ª LLM è°ƒç”¨ï¼Œæµå¼è¾“å‡º
- å…¨èƒ½åŠ›ä¿ç•™ï¼šskillsï¼ˆtool callingï¼‰ã€memory æ£€ç´¢/æ‘„å…¥
- å¤ç”¨å·²æœ‰åŸºç¡€è®¾æ–½ï¼šLLMProviderã€SkillExecutorã€MemoryServiceã€AG-UI äº‹ä»¶
"""

import asyncio
import uuid
import json
from typing import Dict, List, Optional, Any, AsyncGenerator
from datetime import datetime

from core.models import AgentStatus, TaskSession
from llm.provider import LLMProviderFactory, LLMMessage, LLMConfig
from skills import list_skills, get_global_registry
from skills.executor import SkillExecutor, AgentSkillSet
from agui.events import (
    EventFactory,
    BaseEvent,
    RunStartedEvent,
    RunFinishedEvent,
    TextMessageStartEvent,
    TextMessageContentEvent,
    TextMessageEndEvent,
    ToolCallStartEvent,
    ToolCallArgsEvent,
    ToolCallEndEvent,
    ToolCallResultEvent,
    AgentThinkingEvent,
)


# æ™®é€šæ¨¡å¼ç³»ç»Ÿæç¤º
DIRECT_AGENT_SYSTEM_PROMPT = """ä½ æ˜¯ä¸€ä¸ªå¼ºå¤§çš„ AI åŠ©æ‰‹ï¼Œå…·å¤‡ä»¥ä¸‹èƒ½åŠ›ï¼š

## å½“å‰æ—¶é—´
{current_time}

## æ ¸å¿ƒèƒ½åŠ›
1. **æ·±åº¦åˆ†æ**ï¼šèƒ½å¤Ÿæ·±å…¥åˆ†æå¤æ‚é—®é¢˜ï¼Œæä¾›å…¨é¢ã€ä¸“ä¸šçš„è§è§£
2. **æŠ€èƒ½è°ƒç”¨**ï¼šå¯ä»¥è°ƒç”¨å„ç§æŠ€èƒ½å·¥å…·æ¥è¾…åŠ©å®Œæˆä»»åŠ¡ï¼ˆå¦‚ç½‘ç»œæœç´¢ã€æ•°æ®åˆ†æã€ä»£ç æ‰§è¡Œç­‰ï¼‰
3. **è®°å¿†ç³»ç»Ÿ**ï¼šèƒ½è®°ä½ç”¨æˆ·çš„åå¥½å’Œå†å²äº¤äº’

## å·¥ä½œåŸåˆ™
- ç›´æ¥ã€æ¸…æ™°åœ°å›ç­”ç”¨æˆ·é—®é¢˜
- å¿…è¦æ—¶ä¸»åŠ¨è°ƒç”¨å·¥å…·è·å–ä¿¡æ¯ï¼Œå°¤å…¶æ˜¯éœ€è¦å®æ—¶æ•°æ®æ—¶ï¼ˆå¦‚è‚¡ä»·ã€æ–°é—»ã€æœ€æ–°èµ„è®¯ç­‰ï¼‰ï¼ŒåŠ¡å¿…è°ƒç”¨ web-search å·¥å…·
- ä½¿ç”¨ Markdown æ ¼å¼ç»„ç»‡è¾“å‡º
- æä¾›æœ‰æ·±åº¦å’Œå®ç”¨ä»·å€¼çš„å›ç­”

## å¼•ç”¨ä¸æ¥æº
å¦‚æœä½ ä½¿ç”¨äº†æœç´¢å·¥å…·è·å–ä¿¡æ¯ï¼Œ**å¿…é¡»**åœ¨å›å¤æœ«å°¾åˆ—å‡ºå‚è€ƒæ¥æºé“¾æ¥ã€‚æ ¼å¼å¦‚ä¸‹ï¼š

```
## å‚è€ƒæ¥æº
- [æ ‡é¢˜](URL)
- [æ ‡é¢˜](URL)
```

ç¡®ä¿æ¯ä¸ªå¼•ç”¨çš„äº‹å®éƒ½èƒ½è¿½æº¯åˆ°å…·ä½“æ¥æºï¼Œä¸è¦é—æ¼æœç´¢ç»“æœä¸­çš„ URLã€‚

{skills_prompt}

{memory_prompt}
"""


class DirectAgent:
    """
    æ™®é€šæ¨¡å¼ Agent - ç›´æ¥å¯¹è¯ï¼Œä¸æ¶Œç°è§’è‰²
    
    æ”¯æŒï¼š
    - æµå¼ LLM è¾“å‡ºï¼ˆAG-UI äº‹ä»¶æ ¼å¼ï¼‰
    - Skillsï¼ˆé€šè¿‡ tool callingï¼‰
    - Memoryï¼ˆç”¨æˆ·åå¥½è®°å¿†ï¼‰
    """
    
    def __init__(
        self,
        provider_type: str = "openai",
        model: Optional[str] = None,
        session_id: Optional[str] = None,
        user_id: Optional[str] = None,
    ):
        self.provider_type = provider_type
        self.model = model
        self.session_id = session_id or str(uuid.uuid4())
        self.user_id = user_id
        
        # LLM
        self.provider = LLMProviderFactory.get_provider(provider_type)
        self.llm_config = LLMProviderFactory.get_default_config(provider_type)
        if model:
            self.llm_config.model = model
        
        # Skills - åˆ†é…æ‰€æœ‰å¯ç”¨æŠ€èƒ½
        self.agent_id = f"direct-{self.session_id[:8]}"
        self.skill_set = AgentSkillSet(
            agent_id=self.agent_id,
            agent_name="Assistant",
        )
        self._init_all_skills()
        
        # ä¼šè¯ç®¡ç†
        self.sessions: Dict[str, TaskSession] = {}
        self.active_subagents: Dict[str, Any] = {}  # å…¼å®¹ MasterAgent æ¥å£
        
        # å¯¹è¯å†å²ï¼ˆç”¨äºå¤šè½®å¯¹è¯ï¼‰
        self.conversation_history: List[LLMMessage] = []
        
        print(f"[DirectAgent] Created for session: {self.session_id[:8]}...")
    
    def _init_all_skills(self):
        """åˆ†é…æ‰€æœ‰å¯ç”¨æŠ€èƒ½"""
        all_skill_names = list_skills()
        assigned = self.skill_set.assign_skills(all_skill_names)
        if assigned > 0:
            print(f"[DirectAgent] Assigned {assigned} skills: {all_skill_names}")
    
    async def execute_task(self, task: str) -> AsyncGenerator[BaseEvent, None]:
        """
        æ‰§è¡Œä»»åŠ¡ - æ™®é€šæ¨¡å¼

        æµç¨‹ï¼š
        1. æ£€ç´¢ç”¨æˆ·è®°å¿†
        2. æ„å»ºç³»ç»Ÿæç¤ºï¼ˆå«æŠ€èƒ½ä¿¡æ¯ï¼‰
        3. LLM æµå¼ç”Ÿæˆ / tool calling å¾ªç¯
        4. è¾“å‡ºç»“æœ
        
        Yields:
            AG-UI åè®®äº‹ä»¶æµ
        """
        session = TaskSession(task=task)
        self.sessions[session.id] = session
        
        thread_id = session.id
        run_id = str(uuid.uuid4())
        
        # å‘é€å¼€å§‹äº‹ä»¶
        yield EventFactory.run_started(thread_id, run_id)
        
        try:
            # ===== è®°å¿†æ£€ç´¢ =====
            user_memory_text = ""
            if self.user_id:
                try:
                    from memory.service import get_memory_service
                    memory_service = get_memory_service()
                    if memory_service.is_enabled:
                        memories = await memory_service.retrieve(
                            user_id=self.user_id,
                            queries=[task],
                        )
                        user_memory_text = memory_service.format_for_prompt(memories)
                        if user_memory_text:
                            print(f"[DirectAgent] Retrieved user memory for {self.user_id[:8]}...")
                        
                        # æ‘„å…¥ç”¨æˆ·è¾“å…¥
                        asyncio.create_task(memory_service.memorize(
                            user_id=self.user_id,
                            content=f"ç”¨æˆ·ä»»åŠ¡è¯·æ±‚: {task}",
                            modality="conversation",
                        ))
                except Exception as e:
                    print(f"[DirectAgent] Memory retrieval failed (non-blocking): {e}")
            
            # ===== æ„å»ºç³»ç»Ÿæç¤º =====
            skills_prompt = ""
            tool_definitions = self.skill_set.get_tool_definitions()
            if tool_definitions:
                skills_prompt = "## å¯ç”¨å·¥å…·\nä½ å¯ä»¥è°ƒç”¨ä»¥ä¸‹å·¥å…·æ¥è¾…åŠ©å®Œæˆä»»åŠ¡ã€‚"
            
            memory_prompt = ""
            if user_memory_text:
                memory_prompt = f"## ğŸ‘¤ ç”¨æˆ·åå¥½ä¸è®°å¿†\n{user_memory_text}"
            
            system_prompt = DIRECT_AGENT_SYSTEM_PROMPT.format(
                skills_prompt=skills_prompt,
                memory_prompt=memory_prompt,
                current_time=datetime.now().strftime("%Yå¹´%mæœˆ%dæ—¥ %H:%M:%Sï¼ˆ%Aï¼‰"),
            )
            
            # ===== æ„å»ºæ¶ˆæ¯ =====
            messages = [
                LLMMessage(role="system", content=system_prompt),
            ]
            
            # æ·»åŠ å¯¹è¯å†å²
            messages.extend(self.conversation_history)
            
            # æ·»åŠ å½“å‰ä»»åŠ¡
            messages.append(LLMMessage(role="user", content=task))
            
            # ===== æ‰§è¡Œ LLMï¼ˆå¸¦ tool calling å¾ªç¯ï¼‰=====
            session.status = AgentStatus.RUNNING
            
            message_id = f"direct-{run_id}"
            yield TextMessageStartEvent(message_id=message_id, role="assistant")
            
            full_response = ""
            max_tool_rounds = 5
            
            # å·¥å…·è°ƒç”¨å¾ªç¯ï¼šç”¨éæµå¼ chat_complete å¤„ç† tool calling
            for tool_round in range(max_tool_rounds):
                if not tool_definitions:
                    break
                
                print(f"[DirectAgent] Tool round {tool_round + 1}, calling LLM (non-streaming for tool detection)...")
                response = await self.provider.chat_complete(
                    messages, self.llm_config, tools=tool_definitions
                )
                
                content = response.get("content", "")
                tool_calls = response.get("tool_calls")
                
                if not tool_calls:
                    # æ²¡æœ‰å·¥å…·è°ƒç”¨ â†’ ä¸ä½¿ç”¨è¿™ä¸ªéæµå¼ç»“æœï¼Œè·³å‡ºå¾ªç¯èµ°æµå¼è¾“å‡º
                    break
                
                # æœ‰å·¥å…·è°ƒç”¨ï¼šå‘å‡º thinking äº‹ä»¶ï¼ˆLLM åœ¨è°ƒç”¨å·¥å…·å‰çš„åˆ†æï¼‰
                if content:
                    yield AgentThinkingEvent(
                        agent_id=self.agent_id,
                        agent_name="Assistant",
                        thinking=content,
                    )
                
                # å¤„ç†å·¥å…·è°ƒç”¨
                messages.append(LLMMessage(
                    role="assistant",
                    content=content or "",
                    tool_calls=tool_calls
                ))
                
                for tc in tool_calls:
                    tool_call_id = tc["id"]
                    func_name = tc["function"]["name"]
                    func_args_str = tc["function"]["arguments"]
                    
                    # TOOL_CALL_START äº‹ä»¶
                    yield ToolCallStartEvent(
                        tool_call_id=tool_call_id,
                        tool_call_name=func_name,
                        parent_message_id=message_id,
                    )
                    
                    # TOOL_CALL_ARGS äº‹ä»¶
                    yield ToolCallArgsEvent(
                        tool_call_id=tool_call_id,
                        delta=func_args_str if isinstance(func_args_str, str) else json.dumps(func_args_str, ensure_ascii=False),
                    )
                    
                    # æ‰§è¡ŒæŠ€èƒ½
                    try:
                        func_args = json.loads(func_args_str) if isinstance(func_args_str, str) else func_args_str
                        task_desc = func_args.get("task", task)
                        
                        print(f"[DirectAgent] Executing skill: {func_name}, task: {task_desc[:80]}")
                        
                        result = await self.skill_set.execute_skill(
                            skill_name=func_name,
                            task=task_desc,
                            mode=self._get_skill_mode(func_name),
                            script_name=self._get_skill_script(func_name),
                            script_args=self._build_script_args(func_name, func_args),
                        )
                        
                        tool_result_str = result.result if result.success else (result.error or "æ‰§è¡Œå¤±è´¥")
                        
                        print(f"[DirectAgent] Skill {func_name} result: success={result.success}, summary={result.summary}")
                        
                        yield ToolCallEndEvent(tool_call_id=tool_call_id)
                        
                        yield ToolCallResultEvent(
                            tool_call_id=tool_call_id,
                            result=json.dumps({
                                "agent_id": self.agent_id,
                                "agent_name": "Assistant",
                                "skill_name": func_name,
                                "success": result.success,
                                "summary": result.summary or "",
                                "result_preview": str(tool_result_str)[:500] if tool_result_str else "",
                            }, ensure_ascii=False),
                        )
                        
                        messages.append(LLMMessage(
                            role="tool",
                            content=str(tool_result_str) if tool_result_str else "æ— ç»“æœ",
                            tool_call_id=tool_call_id,
                        ))
                        
                    except Exception as e:
                        error_msg = f"æŠ€èƒ½æ‰§è¡Œé”™è¯¯: {str(e)}"
                        print(f"[DirectAgent] Skill {func_name} error: {e}")
                        
                        yield ToolCallEndEvent(tool_call_id=tool_call_id)
                        
                        yield ToolCallResultEvent(
                            tool_call_id=tool_call_id,
                            result=json.dumps({
                                "agent_id": self.agent_id,
                                "agent_name": "Assistant",
                                "skill_name": func_name,
                                "success": False,
                                "summary": error_msg,
                                "result_preview": "",
                            }, ensure_ascii=False),
                        )
                        messages.append(LLMMessage(
                            role="tool",
                            content=error_msg,
                            tool_call_id=tool_call_id,
                        ))
            
            # æœ€ç»ˆæ–‡æœ¬å›å¤ï¼šå§‹ç»ˆç”¨æµå¼è¾“å‡º
            print(f"[DirectAgent] Final streaming response...")
            async for chunk in self.provider.chat(messages, self.llm_config):
                full_response += chunk
                yield TextMessageContentEvent(
                    message_id=message_id,
                    delta=chunk
                )
            
            yield TextMessageEndEvent(message_id=message_id)
            
            # æ›´æ–°å¯¹è¯å†å²
            self.conversation_history.append(LLMMessage(role="user", content=task))
            self.conversation_history.append(LLMMessage(role="assistant", content=full_response))
            
            # ä¿æŒå¯¹è¯å†å²åœ¨åˆç†é•¿åº¦
            if len(self.conversation_history) > 20:
                self.conversation_history = self.conversation_history[-16:]
            
            session.status = AgentStatus.COMPLETED
            session.final_report = full_response
            
            # è®°å¿†æ‘„å…¥
            if self.user_id and full_response:
                try:
                    from memory.service import get_memory_service
                    memory_service = get_memory_service()
                    if memory_service.is_enabled:
                        # direct æ¨¡å¼æ²¡æœ‰ä»‹å…¥æ¶ˆæ¯ï¼Œä¸”å¼€å§‹æ—¶å·²æ‘„å…¥ taskï¼Œç»“æŸæ—¶ä¸é‡å¤æ‘„å…¥
                        pass
                except Exception:
                    pass
            
            yield EventFactory.run_finished(thread_id, run_id)
            
        except Exception as e:
            session.status = AgentStatus.FAILED
            yield TextMessageContentEvent(
                message_id=f"direct-{run_id}",
                delta=f"\n\nâŒ é”™è¯¯: {str(e)}"
            )
            yield TextMessageEndEvent(message_id=f"direct-{run_id}")
            yield EventFactory.run_error(str(e))
    
    def _get_skill_mode(self, skill_name: str) -> str:
        """æ ¹æ®æŠ€èƒ½ååˆ¤æ–­æ‰§è¡Œæ¨¡å¼"""
        registry = get_global_registry()
        skill = registry.get(skill_name)
        if skill and skill.get_scripts():
            return "script"
        return "prompt"
    
    def _get_skill_script(self, skill_name: str) -> Optional[str]:
        """è·å–æŠ€èƒ½è„šæœ¬å"""
        registry = get_global_registry()
        skill = registry.get(skill_name)
        if skill:
            scripts = skill.get_scripts()
            if scripts:
                return scripts[0].name
        return None
    
    def _build_script_args(self, skill_name: str, func_args: Dict) -> Optional[List[str]]:
        """
        æ„å»ºè„šæœ¬å‚æ•°
        
        æ ¹æ®ä¸åŒ skill çš„è„šæœ¬å‚æ•°æ ¼å¼æ„å»ºå‘½ä»¤è¡Œå‚æ•°ã€‚
        ä¾‹å¦‚ web-search çš„ search.py éœ€è¦ --query <keyword> æ ¼å¼ã€‚
        """
        task_desc = func_args.get("task", "")
        
        # web-search skill: search.py éœ€è¦ --query å‚æ•°
        if skill_name == "web-search":
            args = ["--query", task_desc]
            # å¯é€‰å‚æ•°
            options = func_args.get("options", {})
            if isinstance(options, dict):
                if options.get("type"):
                    args.extend(["--type", str(options["type"])])
                if options.get("max_results"):
                    args.extend(["--max-results", str(options["max_results"])])
                if options.get("region"):
                    args.extend(["--region", str(options["region"])])
                if options.get("time_range"):
                    args.extend(["--time-range", str(options["time_range"])])
            # é»˜è®¤è¿”å›æ›´å¤šç»“æœ
            if "--max-results" not in args:
                args.extend(["--max-results", "8"])
            return args
        
        # å…¶ä»– skill ä½¿ç”¨é€šç”¨æ ¼å¼
        if task_desc:
            return [task_desc]
        return None
    
    def get_session_state(self, session_id: str) -> Optional[Dict[str, Any]]:
        """è·å–ä¼šè¯çŠ¶æ€ï¼ˆå…¼å®¹ MasterAgent æ¥å£ï¼‰"""
        if session_id not in self.sessions:
            return None
        session = self.sessions[session_id]
        return {
            "id": session.id,
            "task": session.task,
            "status": session.status.value,
            "plan": None,
            "subagents": {},
            "final_report": session.final_report,
            "created_at": session.created_at.isoformat(),
            "updated_at": session.updated_at.isoformat(),
        }
    
    def get_instance_info(self) -> Dict[str, Any]:
        """è·å–å®ä¾‹ä¿¡æ¯"""
        return {
            "session_id": self.session_id,
            "provider_type": self.provider_type,
            "model": self.model,
            "mode": "direct",
            "skills_count": len(self.skill_set.list_skills()),
            "conversation_turns": len(self.conversation_history) // 2,
        }
    
    def cleanup(self):
        """æ¸…ç†èµ„æº"""
        self.sessions.clear()
        self.conversation_history.clear()
        print(f"[DirectAgent] Session {self.session_id[:8]}... cleaned up")
