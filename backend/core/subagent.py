"""
Subagent è¿è¡Œæ—¶

æ¯ä¸ª Subagent æ˜¯ä¸€ä¸ªç‹¬ç«‹çš„æ‰§è¡Œå•å…ƒï¼Œæ‹¥æœ‰ï¼š
1. æ¶Œç°çš„è§’è‰²å®šä¹‰
2. ç‹¬ç«‹çš„æ€è€ƒå’Œæ‰§è¡Œèƒ½åŠ›
3. è‡ªé€‚åº”ä¸­ç»§è§¦å‘æœºåˆ¶
4. åŠ¨æ€æŠ€èƒ½æ‰§è¡Œèƒ½åŠ›
"""

import asyncio
import json
import uuid
import logging
from typing import Optional, Dict, Any, List, Callable, AsyncGenerator
from datetime import datetime

from core.models import (
    SubagentConfig,
    SubagentState,
    AgentStatus,
    RelayMessage,
    RelayType,
    ToolCall,
    InterventionType,
)
from llm.provider import LLMProviderFactory, LLMMessage, LLMConfig


logger = logging.getLogger(__name__)


class SubagentRuntime:
    """Subagent è¿è¡Œæ—¶"""
    
    def __init__(
        self,
        config: SubagentConfig,
        provider_type: str = "openai",
        model: Optional[str] = None,
        on_thinking: Optional[Callable[[str, str], None]] = None,
        on_progress: Optional[Callable[[str, float, str], None]] = None,
        on_relay_request: Optional[Callable[[RelayMessage], None]] = None,
        on_tool_call: Optional[Callable[[str, ToolCall], None]] = None,
        skill_executor = None,  # æŠ€èƒ½æ‰§è¡Œå™¨
        user_memory: str = "",  # ç”¨æˆ·è®°å¿†åå¥½æ–‡æœ¬
    ):
        """
        Args:
            config: Subagent é…ç½®
            provider_type: LLM æä¾›è€…ç±»å‹
            model: æ¨¡å‹åç§°
            on_thinking: æ€è€ƒè¿‡ç¨‹å›è°ƒ (agent_id, thinking_content)
            on_progress: è¿›åº¦æ›´æ–°å›è°ƒ (agent_id, progress, step)
            on_relay_request: ä¸­ç»§è¯·æ±‚å›è°ƒ
            on_tool_call: å·¥å…·è°ƒç”¨å›è°ƒ
            skill_executor: æŠ€èƒ½æ‰§è¡Œå™¨å®ä¾‹
            user_memory: ç”¨æˆ·è®°å¿†åå¥½æ–‡æœ¬ï¼Œæ³¨å…¥åˆ° system prompt
        """
        self.config = config
        self.state = SubagentState(
            id=config.id,
            config=config,
        )
        
        self.provider = LLMProviderFactory.get_provider(provider_type)
        self.llm_config = LLMProviderFactory.get_default_config(provider_type)
        if model:
            self.llm_config.model = model
        
        # å›è°ƒå‡½æ•°
        self.on_thinking = on_thinking
        self.on_progress = on_progress
        self.on_relay_request = on_relay_request
        self.on_tool_call = on_tool_call
        
        # æŠ€èƒ½æ‰§è¡Œå™¨
        self.skill_executor = skill_executor
        
        # ç”¨æˆ·è®°å¿†åå¥½
        self.user_memory = user_memory
        self._init_skill_set()
        
        # å¯¹è¯å†å²
        self.messages: List[LLMMessage] = []
        
        # æ§åˆ¶æ ‡å¿—
        self._paused = False
        self._cancelled = False
        
        # äººå·¥å¹²é¢„ç›¸å…³
        self._pending_acknowledgements: List[str] = []  # å¾…ç¡®è®¤çš„å¹²é¢„æ¶ˆæ¯ID
        self._intervention_history: List[Dict[str, Any]] = []  # å¹²é¢„å†å²
        
        # ä¸­ç»§æ¶ˆæ¯é˜Ÿåˆ—
        self.relay_inbox: asyncio.Queue = asyncio.Queue()
    
    def _init_skill_set(self):
        """åˆå§‹åŒ–æŠ€èƒ½é›† (v2 æ¶æ„ - SKILL.md æ ¼å¼)
        
        åªæš´éœ² master åˆ†é…ç»™æœ¬ subagent çš„æŠ€èƒ½ï¼Œç¡®ä¿å­ agent 
        æ— æ³•è®¿é—®æœªæˆæƒçš„èƒ½åŠ›ã€‚
        """
        self._tool_definitions: List[Dict[str, Any]] = []  # ä»…å·²åˆ†é…æŠ€èƒ½çš„ tool å®šä¹‰
        self._skill_name_map: Dict[str, str] = {}  # tool function name -> skill name æ˜ å°„
        
        try:
            from skills import AgentSkillSet, SkillExecutor, init_skills
            
            # åˆå§‹åŒ–æŠ€èƒ½åº“ï¼ˆå¦‚æœå°šæœªåˆå§‹åŒ–ï¼‰
            init_skills()
            
            # åˆ›å»ºæŠ€èƒ½é›†
            if self.skill_executor is None:
                self.skill_set = AgentSkillSet(
                    agent_id=self.config.id,
                    agent_name=self.config.role.name
                )
            else:
                self.skill_set = AgentSkillSet(
                    agent_id=self.config.id,
                    agent_name=self.config.role.name,
                    executor=self.skill_executor
                )
            
            # åˆ†é…è§’è‰²é…ç½®çš„æŠ€èƒ½
            for skill_assignment in self.config.role.assigned_skills:
                # v2 æŠ€èƒ½ä½¿ç”¨è¿å­—ç¬¦å‘½åï¼Œå…¼å®¹ä¸‹åˆ’çº¿å‘½å
                skill_name = skill_assignment.skill_name.replace('_', '-')
                self.skill_set.assign_skill(
                    skill_name,
                    skill_assignment.config
                )
            
            # ä»å·²åˆ†é…æŠ€èƒ½ç”Ÿæˆ tool å®šä¹‰ï¼ˆä»…é™å·²åˆ†é…æŠ€èƒ½ï¼‰
            self._tool_definitions = self.skill_set.get_tool_definitions()
            for td in self._tool_definitions:
                func_name = td.get("function", {}).get("name", "")
                if func_name:
                    self._skill_name_map[func_name] = func_name  # skill name == function name
            
            assigned = self.skill_set.list_skills()
            logger.info(
                "Subagent %s skills initialized: assigned=%s, tools=%d",
                self.agent_name, assigned, len(self._tool_definitions),
            )
        except ImportError as e:
            logger.warning(f"æŠ€èƒ½ç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥: {e}")
            self.skill_set = None
    
    @property
    def agent_id(self) -> str:
        return self.config.id
    
    @property
    def agent_name(self) -> str:
        return self.config.role.name
    
    async def run(self) -> SubagentState:
        """æ‰§è¡Œ Subagent ä»»åŠ¡"""
        try:
            self._update_status(AgentStatus.RUNNING)
            self._init_messages()
            
            iteration = 0
            max_iterations = self.config.max_iterations
            
            while iteration < max_iterations and not self._cancelled:
                if self._paused:
                    self._update_status(AgentStatus.PAUSED)
                    await asyncio.sleep(0.5)
                    continue
                
                iteration += 1
                self.state.iterations = iteration
                
                # æ£€æŸ¥ä¸­ç»§æ¶ˆæ¯
                await self._process_relay_inbox()
                
                # æ›´æ–°è¿›åº¦
                progress = min(95, (iteration / max_iterations) * 100)
                self._update_progress(progress, f"è¿­ä»£ {iteration}/{max_iterations}")
                
                # æ‰§è¡Œä¸€æ¬¡ LLM è°ƒç”¨
                response = await self._execute_iteration()
                
                # æ£€æŸ¥æ˜¯å¦å®Œæˆï¼ˆå‡çº§ç‰ˆï¼šå…ˆæ£€æŸ¥ä¸­ç»§ç«™çŠ¶æ€ï¼‰
                task_complete = self._is_task_complete(response)
                
                if task_complete:
                    # å†æ¬¡ç¡®è®¤ä¸­ç»§ç«™çŠ¶æ€
                    has_pending, pending_summary = self._check_pending_relay_messages()
                    
                    if has_pending and not self._can_complete_with_pending_messages(response, pending_summary):
                        # æœ‰å¾…å¤„ç†æ¶ˆæ¯ï¼Œæ³¨å…¥æç¤ºè®© Agent å¤„ç†
                        self.messages.append(LLMMessage(
                            role="user",
                            content=self._build_pending_message_prompt(pending_summary)
                        ))
                        continue
                    
                    # ç¡®è®¤å®Œæˆ
                    self.state.final_result = self._extract_final_result(response)
                    break
                
                # æ£€æŸ¥æ˜¯å¦éœ€è¦è§¦å‘ä¸­ç»§
                if self.config.relay_enabled:
                    await self._check_relay_trigger(response)
                
                # æ·»åŠ ç»§ç»­è¿­ä»£çš„å¼•å¯¼æ¶ˆæ¯
                if iteration < max_iterations - 1:
                    has_pending, pending_summary = self._check_pending_relay_messages()
                    self.messages.append(LLMMessage(
                        role="user",
                        content=self._build_continuation_prompt(
                            iteration, 
                            response,
                            pending_summary if has_pending else None
                        )
                    ))
            
            self._update_status(AgentStatus.COMPLETED)
            self._update_progress(100, "å®Œæˆ")
            
        except asyncio.CancelledError:
            self._update_status(AgentStatus.CANCELLED)
        except Exception as e:
            self.state.error = str(e)
            logger.exception(
                "Subagent failed: id=%s name=%s iterations=%s error=%s",
                self.agent_id,
                self.agent_name,
                self.state.iterations,
                str(e),
            )
            self._update_status(AgentStatus.FAILED)
        
        return self.state
    
    async def run_stream(self) -> AsyncGenerator[Dict[str, Any], None]:
        """æµå¼æ‰§è¡Œ"""
        try:
            self._update_status(AgentStatus.RUNNING)
            yield {"type": "status", "status": AgentStatus.RUNNING.value}
            
            self._init_messages()
            
            iteration = 0
            max_iterations = self.config.max_iterations
            
            while iteration < max_iterations and not self._cancelled:
                if self._paused:
                    self._update_status(AgentStatus.PAUSED)
                    yield {"type": "status", "status": AgentStatus.PAUSED.value}
                    await asyncio.sleep(0.5)
                    continue
                
                iteration += 1
                self.state.iterations = iteration
                
                # å¤„ç†ä¸­ç»§æ¶ˆæ¯
                processed_relay = await self._process_relay_inbox()
                if processed_relay:
                    yield {
                        "type": "relay_processed",
                        "count": len(processed_relay),
                        "has_intervention": any(
                            m.type == RelayType.HUMAN_INTERVENTION 
                            for m in processed_relay
                        )
                    }
                
                # æ›´æ–°è¿›åº¦
                progress = min(95, (iteration / max_iterations) * 100)
                self._update_progress(progress, f"è¿­ä»£ {iteration}/{max_iterations}")
                yield {
                    "type": "progress",
                    "progress": progress,
                    "step": f"è¿­ä»£ {iteration}/{max_iterations}",
                    "iterations": iteration
                }
                
                # æµå¼æ‰§è¡Œï¼ˆæ”¯æŒ tool callingï¼‰â€”â€” å®æ—¶ yield æ‰€æœ‰äº‹ä»¶
                full_response = ""
                accumulated_thinking = ""
                async for event in self._stream_iteration_with_tools():
                    event_type = event["type"]
                    
                    if event_type == "thinking":
                        # å®æ—¶æ¨é€ thinking chunks ç»™å‰ç«¯
                        chunk = event["delta"]
                        accumulated_thinking += chunk
                        self.state.thinking = accumulated_thinking
                        yield event
                        if self.on_thinking:
                            self.on_thinking(self.agent_id, chunk)
                    elif event_type == "final_content":
                        # æœ€ç»ˆå®Œæ•´å†…å®¹ï¼ˆç”¨äºå®Œæˆåˆ¤æ–­ï¼‰
                        full_response = event["content"]
                    else:
                        # tool_call_start, tool_call_result ç­‰äº‹ä»¶ç›´æ¥è½¬å‘
                        yield event
                
                # æ£€æŸ¥æ˜¯å¦å®Œæˆï¼ˆå‡çº§ç‰ˆï¼šå…ˆæ£€æŸ¥ä¸­ç»§ç«™çŠ¶æ€ï¼‰
                task_complete = self._is_task_complete(full_response)
                
                if task_complete:
                    # å†æ¬¡ç¡®è®¤ä¸­ç»§ç«™çŠ¶æ€
                    has_pending, pending_summary = self._check_pending_relay_messages()
                    
                    if has_pending and not self._can_complete_with_pending_messages(full_response, pending_summary):
                        # æœ‰å¾…å¤„ç†æ¶ˆæ¯ï¼Œé€šçŸ¥ Agent éœ€è¦å…ˆå¤„ç†
                        yield {
                            "type": "completion_blocked",
                            "reason": "pending_relay_messages",
                            "pending_summary": pending_summary
                        }
                        
                        # æ³¨å…¥æç¤ºè®© Agent çŸ¥é“éœ€è¦å…ˆå¤„ç†æ¶ˆæ¯
                        self.messages.append(LLMMessage(
                            role="user",
                            content=self._build_pending_message_prompt(pending_summary)
                        ))
                        continue
                    
                    # ç¡®è®¤å®Œæˆ - å…ˆæ›´æ–°çŠ¶æ€å¹¶ yieldï¼Œå†æå–ç»“æœ
                    # è¿™æ ·å‰ç«¯èƒ½ç«‹å³çœ‹åˆ° completed çŠ¶æ€ï¼Œä¸ç”¨ç­‰ _extract_final_result å®Œæˆ
                    self._update_status(AgentStatus.COMPLETED)
                    yield {"type": "status", "status": AgentStatus.COMPLETED.value}
                    
                    self.state.final_result = self._extract_final_result(full_response)
                    yield {"type": "result", "result": self.state.final_result}
                    break
                
                # æ£€æŸ¥ä¸­ç»§è§¦å‘
                if self.config.relay_enabled:
                    relay_msg = await self._check_relay_trigger(full_response)
                    if relay_msg:
                        yield {"type": "relay", "message": relay_msg.model_dump()}
                
                # æ·»åŠ ç»§ç»­è¿­ä»£çš„å¼•å¯¼æ¶ˆæ¯ï¼ˆå¦‚æœè¿˜æ²¡å®Œæˆï¼‰
                if iteration < max_iterations - 1:
                    # æ£€æŸ¥æ˜¯å¦æœ‰å¾…å¤„ç†æ¶ˆæ¯éœ€è¦æé†’
                    has_pending, pending_summary = self._check_pending_relay_messages()
                    continuation_prompt = self._build_continuation_prompt(
                        iteration, 
                        full_response,
                        pending_summary if has_pending else None
                    )
                    self.messages.append(LLMMessage(
                        role="user",
                        content=continuation_prompt
                    ))
            
            # å…œåº•ï¼šå¦‚æœå¾ªç¯æ­£å¸¸é€€å‡ºï¼ˆè¾¾åˆ° max_iterationsï¼‰ä½†æ²¡æœ‰åœ¨å¾ªç¯å†… break
            # æ­¤æ—¶çŠ¶æ€å¯èƒ½è¿˜æœªæ›´æ–°ä¸º COMPLETED
            if self.state.status != AgentStatus.COMPLETED:
                self._update_status(AgentStatus.COMPLETED)
                yield {"type": "status", "status": AgentStatus.COMPLETED.value}
            
        except asyncio.CancelledError:
            self._update_status(AgentStatus.CANCELLED)
            yield {"type": "status", "status": AgentStatus.CANCELLED.value}
        except Exception as e:
            self.state.error = str(e)
            logger.exception(
                "Subagent stream failed: id=%s name=%s iterations=%s error=%s",
                self.agent_id,
                self.agent_name,
                self.state.iterations,
                str(e),
            )
            self._update_status(AgentStatus.FAILED)
            yield {"type": "error", "error": str(e)}
    
    def pause(self):
        """æš‚åœæ‰§è¡Œ"""
        self._paused = True
    
    def resume(self):
        """æ¢å¤æ‰§è¡Œ"""
        self._paused = False
    
    def cancel(self):
        """å–æ¶ˆæ‰§è¡Œ"""
        self._cancelled = True
    
    async def receive_relay_message(self, message: RelayMessage):
        """æ¥æ”¶ä¸­ç»§æ¶ˆæ¯"""
        # æ ‡è®°æ¶ˆæ¯è¢«æ­¤ Agent æŸ¥çœ‹
        message.mark_viewed(self.agent_id)
        
        await self.relay_inbox.put(message)
        self.state.relay_messages_received.append(message.model_dump())
    
    async def receive_intervention(self, message: RelayMessage, intervention=None):
        """æ¥æ”¶äººå·¥å¹²é¢„æ¶ˆæ¯ - ç‰¹æ®Šå¤„ç†é€šé“
        
        è¿™ä¸ªæ–¹æ³•ç”¨äºå¤„ç†éœ€è¦ç‰¹æ®Šå“åº”çš„äººå·¥å¹²é¢„ï¼Œè€Œä¸åªæ˜¯ç®€å•åœ°æ³¨å…¥åˆ°å¯¹è¯ä¸­ã€‚
        
        Args:
            message: ä¸­ç»§æ¶ˆæ¯
            intervention: åŸå§‹å¹²é¢„å¯¹è±¡ï¼ˆå¯é€‰ï¼‰
        """
        # æ ‡è®°æ¶ˆæ¯è¢«æ­¤ Agent æŸ¥çœ‹
        message.mark_viewed(self.agent_id)
        
        # è®°å½•åˆ°æ”¶åˆ°çš„æ¶ˆæ¯ä¸­
        self.state.relay_messages_received.append(message.model_dump())
        
        # æ ‡è®°éœ€è¦ç¡®è®¤
        if message.metadata.get("requires_acknowledgement"):
            self._pending_acknowledgements.append(message.id)
        
        # è®°å½•å¹²é¢„å†å²
        self._intervention_history.append({
            "message_id": message.id,
            "intervention_type": message.metadata.get("intervention_type", "unknown"),
            "priority": message.metadata.get("priority", 5),
            "timestamp": datetime.now().isoformat(),
            "content_preview": message.content[:100]
        })
        
        # æ ¹æ®å¹²é¢„ç±»å‹å†³å®šå¤„ç†æ–¹å¼
        intervention_type = message.metadata.get("intervention_type", "")
        
        if intervention_type == InterventionType.INJECT.value:
            # æ³¨å…¥ä¿¡æ¯ - æ”¾å…¥æ”¶ä»¶ç®±è®©ä¸‹æ¬¡è¿­ä»£å¤„ç†
            await self.relay_inbox.put(message)
        elif intervention_type == InterventionType.ADJUST.value:
            # è°ƒæ•´æŒ‡ä»¤ - ä¹Ÿæ”¾å…¥æ”¶ä»¶ç®±ï¼Œä½†æ ‡è®°ä¼˜å…ˆçº§
            message.importance = max(message.importance, 0.9)
            await self.relay_inbox.put(message)
        else:
            # å…¶ä»–ç±»å‹ï¼ˆæš‚åœ/æ¢å¤/å–æ¶ˆç­‰å·²åœ¨ MasterAgent å±‚å¤„ç†ï¼‰
            # ä»ç„¶æ”¾å…¥æ”¶ä»¶ç®±è®© Agent çŸ¥é“å‘ç”Ÿäº†ä»€ä¹ˆ
            await self.relay_inbox.put(message)
    
    def inject_information(self, information: str):
        """äººå·¥æ³¨å…¥ä¿¡æ¯ - å¢å¼ºç‰ˆ
        
        ç›´æ¥æ³¨å…¥ä¿¡æ¯åˆ° Agent çš„å¯¹è¯å†å²ä¸­ï¼Œ
        ä½¿ç”¨å¼ºè°ƒæ€§æç¤ºç¡®ä¿ Agent å…³æ³¨è¿™ä¸ªä¿¡æ¯
        """
        injection_prompt = f"""âš ï¸ **[é‡è¦ï¼šäººå·¥æ³¨å…¥ä¿¡æ¯]** âš ï¸

ä»¥ä¸‹æ˜¯äººç±»æ“ä½œå‘˜ç›´æ¥æ³¨å…¥ç»™ä½ çš„é‡è¦ä¿¡æ¯ï¼Œè¯·åŠ¡å¿…è®¤çœŸé˜…è¯»å¹¶æ•´åˆåˆ°ä½ çš„å·¥ä½œä¸­ï¼š

---
{information}
---

**ä½ éœ€è¦åšçš„**ï¼š
1. ä»”ç»†é˜…è¯»ä¸Šè¿°æ³¨å…¥çš„ä¿¡æ¯
2. è¯„ä¼°è¿™äº›ä¿¡æ¯ä¸ä½ å½“å‰ä»»åŠ¡çš„ç›¸å…³æ€§  
3. å¦‚æœç›¸å…³ï¼Œå°†å…¶æ•´åˆåˆ°ä½ çš„åˆ†ææˆ–å·¥ä½œä¸­
4. åœ¨ä½ çš„ä¸‹ä¸€è½®è¾“å‡ºä¸­ä½“ç°å¯¹è¿™äº›ä¿¡æ¯çš„è€ƒè™‘
5. å¦‚æœä¿¡æ¯è¦æ±‚ä½ è°ƒæ•´æ–¹å‘æˆ–å…³æ³¨ç‚¹ï¼Œè¯·ç›¸åº”è°ƒæ•´

è¯·ç»§ç»­ä½ çš„å·¥ä½œï¼Œå¹¶è€ƒè™‘ä¸Šè¿°æ³¨å…¥çš„ä¿¡æ¯ã€‚"""
        
        self.messages.append(LLMMessage(
            role="user",
            content=injection_prompt
        ))
        
        # è®°å½•æ³¨å…¥æ¬¡æ•°
        self._injected_info_count = getattr(self, '_injected_info_count', 0) + 1
        print(f"[Subagent {self.agent_id}] Information injected (total: {self._injected_info_count})")
    
    def _init_messages(self):
        """åˆå§‹åŒ–æ¶ˆæ¯"""
        self.messages = [
            LLMMessage(
                role="system",
                content=self._build_system_prompt()
            ),
            LLMMessage(
                role="user",
                content=self._build_task_prompt()
            )
        ]
    
    def _build_system_prompt(self) -> str:
        """æ„å»ºç³»ç»Ÿæç¤º - å¢å¼ºç‰ˆï¼ŒåŒ…å«å®Œæ•´è§’è‰²ä¿¡æ¯å’ŒæŠ€èƒ½"""
        role = self.config.role
        
        # åŸºç¡€èº«ä»½
        prompt_parts = [
            role.system_prompt,
            "",
            f"## ğŸ• å½“å‰æ—¶é—´",
            f"{datetime.now().strftime('%Yå¹´%mæœˆ%dæ—¥ %H:%M:%Sï¼ˆ%Aï¼‰')}",
            "",
            "## ğŸ­ ä½ çš„èº«ä»½",
            f"- **è§’è‰²åç§°**ï¼š{role.name}",
            f"- **ä¸“ä¸šæè¿°**ï¼š{role.description}",
            f"- **ä¸“ä¸šæ°´å¹³**ï¼š{role.expertise_level}",
        ]
        
        # å·¥ä½œç›®æ ‡
        if role.work_objective:
            prompt_parts.extend([
                "",
                "## ğŸ¯ ä½ çš„å·¥ä½œç›®æ ‡",
                role.work_objective,
            ])
        
        # é¢„æœŸäº¤ä»˜ç‰©
        if role.deliverables:
            prompt_parts.extend([
                "",
                "## ğŸ“¦ é¢„æœŸäº¤ä»˜ç‰©",
            ])
            for deliverable in role.deliverables:
                prompt_parts.append(f"- {deliverable}")
        
        # å·¥ä½œæ–¹æ³•è®º
        if role.methodology:
            methodology = role.methodology
            prompt_parts.extend([
                "",
                "## ğŸ“‹ å·¥ä½œæ–¹æ³•è®º",
                f"**æ€»ä½“æ–¹æ³•**ï¼š{methodology.approach}",
            ])
            
            if methodology.steps:
                prompt_parts.append("")
                prompt_parts.append("**å·¥ä½œæ­¥éª¤**ï¼š")
                for i, step in enumerate(methodology.steps, 1):
                    prompt_parts.append(f"{i}. {step}")
            
            if methodology.tools_and_frameworks:
                prompt_parts.append("")
                prompt_parts.append("**ä½¿ç”¨çš„å·¥å…·å’Œæ¡†æ¶**ï¼š")
                for tool in methodology.tools_and_frameworks:
                    prompt_parts.append(f"- {tool}")
            
            if methodology.success_criteria:
                prompt_parts.append("")
                prompt_parts.append("**æˆåŠŸæ ‡å‡†**ï¼š")
                for criteria in methodology.success_criteria:
                    prompt_parts.append(f"- {criteria}")
        
        # æ ¸å¿ƒèƒ½åŠ›
        if role.capabilities:
            prompt_parts.extend([
                "",
                "## ğŸ’ª ä½ çš„æ ¸å¿ƒèƒ½åŠ›",
            ])
            for cap in role.capabilities:
                prompt_parts.append(f"- {cap}")
        
        # å…³æ³¨é¢†åŸŸ
        if role.focus_areas:
            prompt_parts.extend([
                "",
                "## ğŸ” å…³æ³¨é¢†åŸŸ",
            ])
            for area in role.focus_areas:
                prompt_parts.append(f"- {area}")
        
        # æŠ€èƒ½è¯´æ˜
        if role.assigned_skills:
            prompt_parts.extend([
                "",
                "## ğŸ› ï¸ ä½ æ‹¥æœ‰çš„æŠ€èƒ½",
            ])
            for skill in role.assigned_skills:
                prompt_parts.append(f"- **{skill.skill_display_name}** ({skill.skill_name})")
                if skill.reason:
                    prompt_parts.append(f"  ç”¨é€”ï¼š{skill.reason}")
            
            prompt_parts.append("")
            prompt_parts.append("âš ï¸ **æŠ€èƒ½é™åˆ¶**ï¼šä½ åªèƒ½ä½¿ç”¨ä»¥ä¸Šå·²åˆ†é…çš„æŠ€èƒ½ï¼Œä¸å¾—è°ƒç”¨æˆ–å‡è®¾æœªåˆ†é…çš„æŠ€èƒ½èƒ½åŠ›ã€‚")
            
            # æ·»åŠ æŠ€èƒ½ä½¿ç”¨è¯´æ˜
            if self.skill_set:
                skill_injection = self.skill_set.get_system_prompt_injection()
                if skill_injection:
                    prompt_parts.append("")
                    prompt_parts.append(skill_injection)
        
        # å·¥ä½œæ–¹å¼
        prompt_parts.extend([
            "",
            "## ğŸ“ å·¥ä½œè§„èŒƒ",
            "1. æ·±å…¥åˆ†æä½ è¢«åˆ†é…çš„ä»»åŠ¡ï¼Œå‘æŒ¥ä½ çš„ä¸“ä¸šèƒ½åŠ›",
            "2. æŒ‰ç…§ä½ çš„å·¥ä½œæ–¹æ³•è®ºç³»ç»Ÿæ€§åœ°å¼€å±•å·¥ä½œ",
            "3. å½“ä½ æœ‰é‡è¦å‘ç°æ—¶ï¼Œæ˜ç¡®æ ‡æ³¨ **[å…³é”®å‘ç°]**",
            "4. å½“ä½ å®Œæˆä»»åŠ¡æ—¶ï¼Œç”¨ **[ä»»åŠ¡å®Œæˆ]** æ ‡è®°ï¼Œå¹¶ç»™å‡ºå®Œæ•´çš„åˆ†æç»“æœ",
            "5. **å¼•ç”¨ä¸æ¥æº**ï¼šå¦‚æœä½ ä½¿ç”¨äº†æœç´¢å·¥å…·è·å–ä¿¡æ¯ï¼Œå¿…é¡»åœ¨å›å¤æœ«å°¾çš„ **å‚è€ƒæ¥æº** ç« èŠ‚ä¸­åˆ—å‡ºæ‰€å¼•ç”¨çš„é“¾æ¥ã€‚æ ¼å¼å¦‚ä¸‹ï¼š",
            "   ```",
            "   ## å‚è€ƒæ¥æº",
            "   - [æ ‡é¢˜](URL)",
            "   - [æ ‡é¢˜](URL)",
            "   ```",
            "   ç¡®ä¿æ¯ä¸ªå¼•ç”¨çš„äº‹å®éƒ½èƒ½è¿½æº¯åˆ°å…·ä½“æ¥æºï¼Œä¸è¦é—æ¼æœç´¢ç»“æœä¸­çš„ URLã€‚",
        ])
        
        # ä¸­ç»§è§¦å‘æ¡ä»¶
        if role.relay_triggers:
            prompt_parts.extend([
                "",
                "## ğŸ”„ ä¸­ç»§åä½œæœºåˆ¶",
                "### è§¦å‘ä¸­ç»§çš„æ¡ä»¶",
                "å½“å‡ºç°ä»¥ä¸‹æƒ…å†µæ—¶ï¼Œä½ åº”è¯¥ä¸å…¶ä»– Agent äº¤æ¢ä¿¡æ¯ï¼š",
            ])
            for trigger in role.relay_triggers:
                prompt_parts.append(f"- {trigger}")
            
            prompt_parts.extend([
                "",
                "### ä¸­ç»§æ¶ˆæ¯æ ¼å¼",
                "**1. è¯·æ±‚å¯¹é½ï¼ˆå‘å…¶ä»–Agentè¯·æ±‚ååŠ©ï¼‰**ï¼š",
                "```",
                "[è¯·æ±‚ä¸­ç»§: ç®€çŸ­è¯´æ˜è¯·æ±‚åŸå› ]",
                "å…·ä½“æè¿°ä½ éœ€è¦ä»€ä¹ˆä¿¡æ¯æˆ–ç¡®è®¤ï¼Œä¾‹å¦‚ï¼š",
                "- éœ€è¦å“ªä¸ªè§’è‰²ç¡®è®¤ä»€ä¹ˆå†…å®¹",
                "- ä½ ç›®å‰çš„åˆ†æå‘ç°æ˜¯ä»€ä¹ˆ",
                "- å…·ä½“çš„é—®é¢˜æˆ–ç–‘é—®",
                "```",
                "",
                "**2. å“åº”å¯¹é½ï¼ˆå›å¤å…¶ä»–Agentçš„è¯·æ±‚ï¼‰**ï¼š",
                "```",
                "[å“åº”å¯¹é½: é’ˆå¯¹XXXçš„è¯·æ±‚]",
                "ä½ çš„å…·ä½“å›å¤å†…å®¹ï¼š",
                "- å¯¹é—®é¢˜çš„ç›´æ¥å›ç­”",
                "- ä½ çš„ç›¸å…³å‘ç°æˆ–åˆ†æ",
                "- è¡¥å……ä¿¡æ¯æˆ–å»ºè®®",
                "```",
                "",
                "**3. åˆ†äº«å‘ç°ï¼ˆä¸»åŠ¨åˆ†äº«é‡è¦ä¿¡æ¯ï¼‰**ï¼š",
                "```",
                "[å…³é”®å‘ç°]",
                "è¯¦ç»†æè¿°ä½ çš„å‘ç°å†…å®¹ï¼Œç¡®ä¿ä¿¡æ¯å®Œæ•´æœ‰æ„ä¹‰ã€‚",
                "```",
                "",
                "âš ï¸ **é‡è¦**ï¼šæ‰€æœ‰ä¸­ç»§æ¶ˆæ¯å¿…é¡»åŒ…å«å®Œæ•´ã€å…·ä½“çš„å†…å®¹ï¼Œä¸è¦åªå†™ç§°å‘¼æˆ–ç©ºæ³›çš„ç¡®è®¤ã€‚",
            ])
        
        # æ³¨å…¥ç”¨æˆ·è®°å¿†åå¥½
        if self.user_memory:
            prompt_parts.extend([
                "",
                "## ğŸ‘¤ ç”¨æˆ·åå¥½ä¸è®°å¿†",
                "ä»¥ä¸‹æ˜¯å…³äºå½“å‰ç”¨æˆ·çš„åå¥½å’Œå†å²è®°å¿†ä¿¡æ¯ï¼Œè¯·åœ¨æ‰§è¡Œä»»åŠ¡æ—¶å……åˆ†è€ƒè™‘è¿™äº›ä¿¡æ¯ï¼š",
                self.user_memory,
            ])
        
        return "\n".join(prompt_parts)
    
    def _build_task_prompt(self) -> str:
        """æ„å»ºä»»åŠ¡æç¤º"""
        role = self.config.role
        
        prompt_parts = [
            "## ğŸ¯ ä½ çš„ä»»åŠ¡",
            self.config.task_segment,
            "",
        ]
        
        # å¦‚æœæœ‰äº¤ä»˜ç‰©è¦æ±‚ï¼Œæé†’
        if role.deliverables:
            prompt_parts.extend([
                "## ğŸ“¦ è¯·ç¡®ä¿ä½ çš„è¾“å‡ºåŒ…å«",
            ])
            for deliverable in role.deliverables:
                prompt_parts.append(f"- {deliverable}")
            prompt_parts.append("")
        
        prompt_parts.extend([
            "## ğŸ“ å·¥ä½œæµç¨‹è¯´æ˜",
            "1. ä½ éœ€è¦è¿›è¡Œæ·±å…¥ã€å¤šè½®çš„åˆ†æï¼Œä¸è¦æ€¥äºç»™å‡ºæœ€ç»ˆç»“è®º",
            "2. æ¯è½®åˆ†æåï¼Œæˆ‘ä¼šè¯¢é—®ä½ æ˜¯å¦éœ€è¦ç»§ç»­æ·±å…¥æˆ–æœ‰æ–°çš„å‘ç°",
            "3. å½“ä½ è®¤ä¸ºåˆ†æå·²ç»å®Œæ•´ä¸”æ·±å…¥æ—¶ï¼Œä½¿ç”¨ **[ä»»åŠ¡å®Œæˆ]** æ ‡è®°ï¼Œå¹¶ç»™å‡ºå®Œæ•´çš„åˆ†æç»“æœ",
            "4. å¦‚æœå‘ç°é‡è¦ä¿¡æ¯éœ€è¦ä¸å…¶ä»– Agent å…±äº«ï¼Œè¯·ä½¿ç”¨ **[å…³é”®å‘ç°]** æ ‡è®°",
            "",
            "è¯·å¼€å§‹ä½ çš„ç¬¬ä¸€è½®åˆ†æï¼Œå…ˆä»æ•´ä½“æ¡†æ¶å…¥æ‰‹ï¼Œé€æ­¥æ·±å…¥ã€‚",
        ])
        
        return "\n".join(prompt_parts)
    
    async def _execute_iteration(self) -> str:
        """æ‰§è¡Œä¸€æ¬¡è¿­ä»£ï¼ˆæ”¯æŒ tool callingï¼‰
        
        å¦‚æœ subagent æœ‰å·²åˆ†é…æŠ€èƒ½çš„ tool å®šä¹‰ï¼Œä¼šå°† tools ä¼ é€’ç»™ LLMï¼Œ
        å¹¶åœ¨ LLM è¿”å› tool_calls æ—¶è‡ªåŠ¨æ‰§è¡Œå¯¹åº”æŠ€èƒ½ã€å°†ç»“æœåé¦ˆç»™ LLMã€‚
        """
        tools = self._tool_definitions if self._tool_definitions else None
        max_tool_rounds = 3  # å•æ¬¡è¿­ä»£æœ€å¤šæ‰§è¡Œ 3 è½®å·¥å…·è°ƒç”¨
        
        for tool_round in range(max_tool_rounds + 1):
            response = await self.provider.chat_complete(
                self.messages, self.llm_config, tools=tools
            )
            content = response.get("content", "")
            tool_calls = response.get("tool_calls")
            
            if not tool_calls or not self.skill_set:
                # æ²¡æœ‰å·¥å…·è°ƒç”¨æˆ–æ— æŠ€èƒ½é›†ï¼Œç›´æ¥è¿”å›æ–‡æœ¬å“åº”
                self.messages.append(LLMMessage(role="assistant", content=content))
                self.state.thinking = content
                self.state.partial_result = content
                if self.on_thinking:
                    self.on_thinking(self.agent_id, content)
                return content
            
            # æœ‰å·¥å…·è°ƒç”¨ => æ‰§è¡ŒæŠ€èƒ½å¹¶ç»§ç»­å¯¹è¯
            logger.info(
                "Subagent %s tool calls: %s",
                self.agent_name,
                [tc.get("function", {}).get("name") for tc in tool_calls],
            )
            
            # è®°å½• assistant æ¶ˆæ¯ï¼ˆå¸¦ tool_callsï¼‰
            self.messages.append(LLMMessage(
                role="assistant",
                content=content or "",
                tool_calls=tool_calls,
            ))
            
            # æ‰§è¡Œæ¯ä¸ªå·¥å…·è°ƒç”¨
            for tc in tool_calls:
                tc_id = tc.get("id", str(uuid.uuid4()))
                func_name = tc.get("function", {}).get("name", "")
                func_args_str = tc.get("function", {}).get("arguments", "{}")
                
                try:
                    func_args = json.loads(func_args_str) if isinstance(func_args_str, str) else func_args_str
                except json.JSONDecodeError:
                    func_args = {"task": func_args_str}
                
                skill_name = self._skill_name_map.get(func_name, func_name)
                task_desc = func_args.get("task", func_args.get("query", str(func_args)))
                
                logger.info("Subagent %s executing skill: %s task=%s", self.agent_name, skill_name, task_desc[:100])
                
                # å›è°ƒé€šçŸ¥
                if self.on_tool_call:
                    self.on_tool_call(self.agent_id, ToolCall(
                        id=tc_id,
                        name=func_name,
                        arguments=func_args if isinstance(func_args, dict) else {"task": str(func_args)},
                    ))
                
                # é€šè¿‡ AgentSkillSet æ‰§è¡ŒæŠ€èƒ½ï¼ˆç¡®ä¿æƒé™æ£€æŸ¥ï¼‰
                try:
                    # åˆ¤æ–­æŠ€èƒ½æ˜¯å¦æœ‰è„šæœ¬å¯æ‰§è¡Œ
                    skill_name_str = skill_name or func_name
                    skill_obj = self.skill_set.executor.registry.get(skill_name_str)
                    has_scripts = skill_obj and len(skill_obj.get_scripts()) > 0
                    
                    if has_scripts and skill_obj is not None:
                        # æœ‰è„šæœ¬ => ç”¨ hybrid æˆ– script æ¨¡å¼æ‰§è¡Œ
                        scripts = skill_obj.get_scripts()
                        script_name = scripts[0].path.split("/")[-1] if scripts else None
                        
                        # æ„å»ºè„šæœ¬å‚æ•°
                        script_args = self._build_script_args(skill_name_str, func_args)
                        
                        result = await self.skill_set.execute_skill(
                            skill_name=skill_name_str,
                            task=task_desc,
                            mode="script",
                            script_name=script_name,
                            script_args=script_args,
                        )
                    else:
                        # æ— è„šæœ¬ => prompt æ³¨å…¥æ¨¡å¼
                        result = await self.skill_set.execute_skill(
                            skill_name=skill_name_str,
                            task=task_desc,
                            mode="prompt",
                        )
                    
                    tool_result_content = json.dumps({
                        "success": result.success,
                        "result": result.result,
                        "summary": result.summary,
                        "error": result.error,
                    }, ensure_ascii=False)
                except Exception as e:
                    logger.error("Skill execution error: %s %s", skill_name, e)
                    tool_result_content = json.dumps({
                        "success": False,
                        "error": str(e),
                    }, ensure_ascii=False)
                
                # æ·»åŠ  tool ç»“æœæ¶ˆæ¯
                self.messages.append(LLMMessage(
                    role="tool",
                    content=tool_result_content,
                    tool_call_id=tc_id,
                    name=func_name,
                ))
            
            # å·¥å…·ç»“æœå·²åŠ å…¥æ¶ˆæ¯ï¼Œç»§ç»­ä¸‹ä¸€è½®è®© LLM æ¶ˆåŒ–ç»“æœ
        
        # è¾¾åˆ°æœ€å¤§å·¥å…·è½®æ¬¡ï¼Œåšä¸€æ¬¡ä¸å¸¦ tools çš„è°ƒç”¨è·å–æœ€ç»ˆå›å¤
        response = await self.provider.chat_complete(self.messages, self.llm_config)
        content = response.get("content", "")
        self.messages.append(LLMMessage(role="assistant", content=content))
        self.state.thinking = content
        self.state.partial_result = content
        if self.on_thinking:
            self.on_thinking(self.agent_id, content)
        return content
    
    def _build_script_args(self, skill_name: str, func_args: Dict[str, Any]) -> List[str]:
        """æ ¹æ®æŠ€èƒ½åå’Œå‡½æ•°å‚æ•°æ„å»ºè„šæœ¬å‘½ä»¤è¡Œå‚æ•°"""
        args = []
        
        if skill_name == "web-search":
            query = func_args.get("task", func_args.get("query", ""))
            args.extend(["--query", query])
            if "max_results" in func_args:
                args.extend(["--max-results", str(func_args["max_results"])])
            if "type" in func_args:
                args.extend(["--type", func_args["type"]])
            if "region" in func_args:
                args.extend(["--region", func_args["region"]])
            if "time_range" in func_args:
                args.extend(["--time-range", func_args["time_range"]])
            # é»˜è®¤ JSON è¾“å‡º
            args.extend(["--format", "json"])
        else:
            # é€šç”¨ï¼šå°† task ä½œä¸ºå‚æ•°
            task = func_args.get("task", "")
            if task:
                args.extend(["--task", task])
        
        return args
    
    async def _stream_iteration_with_tools(self) -> AsyncGenerator[Dict[str, Any], None]:
        """æµå¼è¿­ä»£ + tool calling æ”¯æŒ
        
        æ”¹ä¸º AsyncGeneratorï¼Œå®æ—¶ yield äº‹ä»¶ï¼š
        - thinking: LLM çš„ä¸­é—´æ€è€ƒ/åˆ†æï¼ˆå·¥å…·å†³ç­–æ—¶çš„ contentï¼‰
        - tool_call_start / tool_call_result: å·¥å…·è°ƒç”¨è¿‡ç¨‹
        - final_content: æœ€ç»ˆæ— å·¥å…·è°ƒç”¨æ—¶çš„å®Œæ•´å›å¤ï¼ˆç”¨äºå®Œæˆåˆ¤æ–­ï¼‰
        
        æœ€ç»ˆå›å¤èµ°æµå¼ chat()ï¼Œå®æ—¶æ¨é€ç»™å‰ç«¯ã€‚
        """
        tools = self._tool_definitions if self._tool_definitions else None
        max_tool_rounds = 3
        
        # å·¥å…·è°ƒç”¨å¾ªç¯ï¼šç”¨éæµå¼æ£€æµ‹ tool_calls
        for tool_round in range(max_tool_rounds):
            if not tools or not self.skill_set:
                break
            
            response = await self.provider.chat_complete(
                self.messages, self.llm_config, tools=tools
            )
            content = response.get("content", "")
            tool_calls = response.get("tool_calls")
            
            if not tool_calls:
                # æ— å·¥å…·è°ƒç”¨ â†’ è·³å‡ºå¾ªç¯èµ°æµå¼æœ€ç»ˆè¾“å‡º
                break
            
            # æœ‰å·¥å…·è°ƒç”¨ï¼šå…ˆæ¨é€ LLM çš„å†³ç­–æ€è€ƒï¼ˆcontent æ˜¯è°ƒç”¨å·¥å…·å‰çš„åˆ†æï¼‰
            if content:
                yield {"type": "thinking", "delta": content}
            
            logger.info(
                "Subagent %s stream tool calls: %s",
                self.agent_name,
                [tc.get("function", {}).get("name") for tc in tool_calls],
            )
            
            self.messages.append(LLMMessage(
                role="assistant",
                content=content or "",
                tool_calls=tool_calls,
            ))
            
            for tc in tool_calls:
                tc_id = tc.get("id", str(uuid.uuid4()))
                func_name = tc.get("function", {}).get("name", "")
                func_args_str = tc.get("function", {}).get("arguments", "{}")
                
                try:
                    func_args = json.loads(func_args_str) if isinstance(func_args_str, str) else func_args_str
                except json.JSONDecodeError:
                    func_args = {"task": func_args_str}
                
                skill_name = self._skill_name_map.get(func_name, func_name)
                task_desc = func_args.get("task", func_args.get("query", str(func_args)))
                
                logger.info("Stream subagent %s executing skill: %s task=%s", self.agent_name, skill_name, task_desc[:100])
                
                # å®æ—¶æ¨é€ tool_call_start
                yield {
                    "type": "tool_call_start",
                    "tool_call_id": tc_id,
                    "tool_name": func_name,
                    "skill_name": skill_name or func_name,
                    "arguments": func_args if isinstance(func_args, dict) else {"task": str(func_args)},
                }
                
                if self.on_tool_call:
                    self.on_tool_call(self.agent_id, ToolCall(
                        id=tc_id,
                        name=func_name,
                        arguments=func_args if isinstance(func_args, dict) else {"task": str(func_args)},
                    ))
                
                try:
                    skill_name_str = skill_name or func_name
                    skill_obj = self.skill_set.executor.registry.get(skill_name_str)
                    has_scripts = skill_obj and len(skill_obj.get_scripts()) > 0
                    
                    if has_scripts and skill_obj is not None:
                        scripts = skill_obj.get_scripts()
                        script_name = scripts[0].path.split("/")[-1] if scripts else None
                        script_args = self._build_script_args(skill_name_str, func_args)
                        
                        result = await self.skill_set.execute_skill(
                            skill_name=skill_name_str,
                            task=task_desc,
                            mode="script",
                            script_name=script_name,
                            script_args=script_args,
                        )
                    else:
                        result = await self.skill_set.execute_skill(
                            skill_name=skill_name_str,
                            task=task_desc,
                            mode="prompt",
                        )
                    
                    tool_result_content = json.dumps({
                        "success": result.success,
                        "result": result.result,
                        "summary": result.summary,
                        "error": result.error,
                    }, ensure_ascii=False)
                    
                    # å®æ—¶æ¨é€ tool_call_result
                    yield {
                        "type": "tool_call_result",
                        "tool_call_id": tc_id,
                        "tool_name": func_name,
                        "skill_name": skill_name or func_name,
                        "success": result.success,
                        "summary": result.summary or "",
                        "result_preview": (result.result or "")[:500],
                    }
                except Exception as e:
                    logger.error("Stream skill execution error: %s %s", skill_name, e)
                    tool_result_content = json.dumps({
                        "success": False,
                        "error": str(e),
                    }, ensure_ascii=False)
                    
                    yield {
                        "type": "tool_call_result",
                        "tool_call_id": tc_id,
                        "tool_name": func_name,
                        "skill_name": skill_name or func_name,
                        "success": False,
                        "summary": f"Error: {str(e)}",
                        "result_preview": "",
                    }
                
                self.messages.append(LLMMessage(
                    role="tool",
                    content=tool_result_content,
                    tool_call_id=tc_id,
                    name=func_name,
                ))
        
        # æœ€ç»ˆå›å¤ï¼šèµ°æµå¼ chat()ï¼Œå®æ—¶æ¨é€ thinking chunks
        full_response = ""
        async for chunk in self.provider.chat(self.messages, self.llm_config):
            full_response += chunk
            yield {"type": "thinking", "delta": chunk}
        
        self.messages.append(LLMMessage(role="assistant", content=full_response))
        
        # æ ‡è®°æœ€ç»ˆå†…å®¹ï¼ˆä¾› run_stream åˆ¤æ–­å®Œæˆå’Œæå–ç»“æœï¼‰
        yield {"type": "final_content", "content": full_response}
    
    def _is_task_complete(self, response: str) -> bool:
        """æ£€æŸ¥ä»»åŠ¡æ˜¯å¦å®Œæˆ
        
        åˆ¤æ–­æ ‡å‡†æ›´ä¸¥æ ¼ï¼š
        1. éœ€è¦æ˜ç¡®çš„å®Œæˆæ ‡è®°
        2. å¿…é¡»å…ˆæ£€æŸ¥ä¸­ç»§ç«™æ˜¯å¦æœ‰å¾…å¤„ç†çš„æ¶ˆæ¯
        3. ç»“åˆæ¶ˆæ¯å†…å®¹å’ŒæŒ‡ä»¤æ¥å†³å®šæ˜¯å¦çœŸæ­£å®Œæˆ
        """
        # é¦–å…ˆæ£€æŸ¥ä¸­ç»§ç«™æ˜¯å¦æœ‰å¾…å¤„ç†çš„æ¶ˆæ¯
        has_pending, pending_summary = self._check_pending_relay_messages()
        
        if has_pending:
            # æœ‰å¾…å¤„ç†çš„ä¸­ç»§æ¶ˆæ¯ï¼Œä¸èƒ½ç›´æ¥å®Œæˆ
            # éœ€è¦æ ¹æ®æ¶ˆæ¯ç±»å‹å’Œå†…å®¹å†³å®šæ˜¯å¦å¯ä»¥å®Œæˆ
            can_complete = self._can_complete_with_pending_messages(response, pending_summary)
            if not can_complete:
                return False
        
        # ä¸¥æ ¼æ¨¡å¼ï¼šå¿…é¡»æ˜¯æ˜ç¡®çš„å®Œæˆæ ‡è®°
        strict_markers = ["[ä»»åŠ¡å®Œæˆ]", "[TASK_COMPLETE]", "**ä»»åŠ¡å®Œæˆ**", "## ä»»åŠ¡å®Œæˆ"]
        
        # æ£€æŸ¥ä¸¥æ ¼æ ‡è®°
        if any(marker in response for marker in strict_markers):
            return True
        
        # å®½æ¾æ£€æŸ¥ï¼šåªæœ‰åœ¨è¿­ä»£æ¬¡æ•°è¾¾åˆ°ä¸€å®šé˜ˆå€¼åæ‰ç”Ÿæ•ˆ
        # è¿™ç¡®ä¿ Agent è‡³å°‘è¿›è¡Œäº†è¶³å¤Ÿçš„æ€è€ƒ
        if self.state.iterations >= 3:
            # æ£€æŸ¥æ˜¯å¦æœ‰å®Œæ•´çš„åˆ†æç»“è®º
            conclusion_patterns = [
                "ç»¼ä¸Šæ‰€è¿°",
                "æ€»ç»“å¦‚ä¸‹", 
                "æœ€ç»ˆç»“è®º",
                "åˆ†ææŠ¥å‘Š",
                "å®Œæ•´åˆ†æç»“æœ"
            ]
            # éœ€è¦åŒæ—¶æ»¡è¶³ï¼šæœ‰ç»“è®ºæ€§è¯æ±‡ + å†…å®¹è¶³å¤Ÿé•¿ï¼ˆè¡¨ç¤ºå®Œæ•´åˆ†æï¼‰
            has_conclusion = any(p in response for p in conclusion_patterns)
            is_substantial = len(response) > 800  # ç¡®ä¿æ˜¯å®è´¨æ€§çš„å†…å®¹
            if has_conclusion and is_substantial:
                return True
        
        return False
    
    def _check_pending_relay_messages(self) -> tuple[bool, Dict[str, Any]]:
        """æ£€æŸ¥ä¸­ç»§ç«™æ˜¯å¦æœ‰å¾…å¤„ç†çš„æ¶ˆæ¯
        
        Returns:
            (has_pending, summary): æ˜¯å¦æœ‰å¾…å¤„ç†æ¶ˆæ¯ï¼Œä»¥åŠæ¶ˆæ¯æ‘˜è¦
        """
        summary = {
            "total_count": 0,
            "intervention_count": 0,
            "high_priority_count": 0,
            "unacknowledged_count": len(self._pending_acknowledgements),
            "message_types": [],
            "interventions": [],
            "requires_response": False,
        }
        
        # æ£€æŸ¥é˜Ÿåˆ—ä¸­çš„æ¶ˆæ¯ï¼ˆä¸å–å‡ºï¼Œåªçª¥è§†ï¼‰
        pending_messages = []
        temp_queue = asyncio.Queue()
        
        while not self.relay_inbox.empty():
            try:
                message = self.relay_inbox.get_nowait()
                pending_messages.append(message)
                temp_queue.put_nowait(message)
            except asyncio.QueueEmpty:
                break
        
        # å°†æ¶ˆæ¯æ”¾å›åŸé˜Ÿåˆ—
        while not temp_queue.empty():
            try:
                message = temp_queue.get_nowait()
                self.relay_inbox.put_nowait(message)
            except asyncio.QueueEmpty:
                break
        
        summary["total_count"] = len(pending_messages)
        
        for msg in pending_messages:
            msg_type = msg.type.value if hasattr(msg.type, 'value') else str(msg.type)
            summary["message_types"].append(msg_type)
            
            # ç»Ÿè®¡äººå·¥å¹²é¢„
            if msg.type == RelayType.HUMAN_INTERVENTION:
                summary["intervention_count"] += 1
                intervention_type = msg.metadata.get("intervention_type", "unknown")
                priority = msg.metadata.get("priority", 5)
                summary["interventions"].append({
                    "type": intervention_type,
                    "priority": priority,
                    "content_preview": msg.content[:100]
                })
                
                # é«˜ä¼˜å…ˆçº§å¹²é¢„éœ€è¦å“åº”
                if priority >= 7:
                    summary["high_priority_count"] += 1
                    summary["requires_response"] = True
            
            # é«˜é‡è¦æ€§æ¶ˆæ¯éœ€è¦å¤„ç†
            if msg.importance >= 0.8:
                summary["high_priority_count"] += 1
        
        # åˆ¤æ–­æ˜¯å¦æœ‰å¾…å¤„ç†æ¶ˆæ¯
        has_pending = (
            summary["total_count"] > 0 or 
            summary["unacknowledged_count"] > 0
        )
        
        return has_pending, summary
    
    def _can_complete_with_pending_messages(
        self, 
        response: str, 
        pending_summary: Dict[str, Any]
    ) -> bool:
        """åˆ¤æ–­åœ¨æœ‰å¾…å¤„ç†æ¶ˆæ¯çš„æƒ…å†µä¸‹æ˜¯å¦å¯ä»¥å®Œæˆä»»åŠ¡
        
        æ ¸å¿ƒé€»è¾‘ï¼š
        1. æœ‰é«˜ä¼˜å…ˆçº§äººå·¥å¹²é¢„ -> ä¸èƒ½å®Œæˆï¼Œå¿…é¡»å…ˆå¤„ç†
        2. æœ‰æœªç¡®è®¤çš„å¹²é¢„æ¶ˆæ¯ -> ä¸èƒ½å®Œæˆ
        3. æœ‰æ™®é€šä¸­ç»§æ¶ˆæ¯ -> æ£€æŸ¥å“åº”æ˜¯å¦å·²ç»è€ƒè™‘äº†è¿™äº›æ¶ˆæ¯
        
        Args:
            response: å½“å‰çš„ LLM å“åº”
            pending_summary: å¾…å¤„ç†æ¶ˆæ¯æ‘˜è¦
        
        Returns:
            æ˜¯å¦å¯ä»¥å®Œæˆ
        """
        # è§„åˆ™1: æœ‰é«˜ä¼˜å…ˆçº§å¹²é¢„ï¼Œå¿…é¡»å…ˆå¤„ç†
        if pending_summary["high_priority_count"] > 0:
            return False
        
        # è§„åˆ™2: æœ‰æœªç¡®è®¤çš„å¹²é¢„æ¶ˆæ¯ï¼Œä¸èƒ½å®Œæˆ
        if pending_summary["unacknowledged_count"] > 0:
            return False
        
        # è§„åˆ™3: æœ‰äººå·¥å¹²é¢„éœ€è¦å“åº”
        if pending_summary["requires_response"]:
            return False
        
        # è§„åˆ™4: æ£€æŸ¥æ˜¯å¦æœ‰éœ€è¦å¤„ç†çš„å¹²é¢„ç±»å‹
        blocking_intervention_types = [
            InterventionType.INJECT.value,
            InterventionType.ADJUST.value,
        ]
        for intervention in pending_summary.get("interventions", []):
            if intervention["type"] in blocking_intervention_types:
                return False
        
        # è§„åˆ™5: å¦‚æœå“åº”ä¸­æ˜ç¡®è¡¨ç¤ºå·²å¤„ç†ä¸­ç»§æ¶ˆæ¯ï¼Œåˆ™å¯ä»¥å®Œæˆ
        acknowledgement_patterns = [
            "å·²æ”¶åˆ°ä¸­ç»§æ¶ˆæ¯",
            "å·²æ•´åˆä¸­ç»§ä¿¡æ¯",
            "å·²è€ƒè™‘äººå·¥å¹²é¢„",
            "å·²æ ¹æ®å¹²é¢„è°ƒæ•´",
            "æ”¶åˆ°å¹²é¢„é€šçŸ¥",
            "å·²ç¡®è®¤æ”¶åˆ°",
        ]
        if any(pattern in response for pattern in acknowledgement_patterns):
            return True
        
        # è§„åˆ™6: åªæœ‰æ™®é€šä½ä¼˜å…ˆçº§æ¶ˆæ¯ï¼Œä¸”å“åº”è¶³å¤Ÿå®Œæ•´ï¼Œå¯ä»¥å®Œæˆ
        # ï¼ˆAgent ä¼šåœ¨ä¸‹ä¸€è½®è‡ªç„¶å¤„ç†è¿™äº›æ¶ˆæ¯ï¼‰
        if (
            pending_summary["intervention_count"] == 0 and
            pending_summary["total_count"] <= 2 and
            len(response) > 500
        ):
            return True
        
        # é»˜è®¤ï¼šæœ‰å¾…å¤„ç†æ¶ˆæ¯æ—¶ä¸èƒ½å®Œæˆ
        return False
    
    def _extract_final_result(self, response: str) -> str:
        """æå–æœ€ç»ˆç»“æœ"""
        # å°è¯•æå– [ä»»åŠ¡å®Œæˆ] ä¹‹åçš„å†…å®¹
        markers = ["[ä»»åŠ¡å®Œæˆ]", "[TASK_COMPLETE]"]
        for marker in markers:
            if marker in response:
                idx = response.index(marker)
                return response[idx:].strip()
        
        # å¦‚æœæ²¡æœ‰æ ‡è®°ï¼Œè¿”å›æ•´ä¸ªå“åº”
        return response
    
    def _is_meaningless_content(self, content: str) -> bool:
        """æ£€æŸ¥å†…å®¹æ˜¯å¦æ— æ„ä¹‰
        
        ç”¨äºè¿‡æ»¤æ‰æ— æ•ˆçš„ä¸­ç»§æ¶ˆæ¯å†…å®¹
        """
        if not content:
            return True
        
        # å»é™¤ç©ºç™½å’Œæ ‡ç‚¹åæ£€æŸ¥
        cleaned = content.strip()
        
        # å¤ªçŸ­
        if len(cleaned) < 5:
            return True
        
        # åªåŒ…å«ç¬¦å·/æ ‡ç‚¹
        import re
        if re.match(r'^[\s\*\#\-\=\_\.\,\ã€‚\ï¼Œ\ã€\ï¼›\ï¼š\"\"\'\'\ï¼ˆ\ï¼‰\ã€\ã€‘\ã€Š\ã€‹\ï¼\ï¼Ÿ]+$', cleaned):
            return True
        
        # åªåŒ…å« markdown æ ¼å¼ç¬¦å·
        if re.match(r'^[\*\#\-\>\s]+$', cleaned):
            return True
        
        # å¸¸è§æ— æ„ä¹‰æ¨¡å¼
        meaningless_patterns = [
            r'^\*+$',           # åªæœ‰æ˜Ÿå·
            r'^#+$',            # åªæœ‰äº•å·
            r'^-+$',            # åªæœ‰æ¨ªçº¿
            r'^\s*$',           # åªæœ‰ç©ºç™½
            r'^\.+$',           # åªæœ‰ç‚¹
            r'^\(.*\)$',        # åªæœ‰æ‹¬å·å†…å®¹ä¸”å¾ˆçŸ­
        ]
        
        for pattern in meaningless_patterns:
            if re.match(pattern, cleaned):
                return True
        
        return False
    
    def _is_semantically_incomplete(self, content: str, is_response_type: bool = False) -> bool:
        """æ£€æŸ¥å†…å®¹æ˜¯å¦è¯­ä¹‰ä¸å®Œæ•´
        
        æ£€æµ‹é‚£äº›å¼•ç”¨äº†åç»­å†…å®¹ä½†å®é™…æ²¡æœ‰åŒ…å«çš„æƒ…å†µ
        ä¾‹å¦‚ï¼š"ä»¥ä¸‹é—®é¢˜"ã€"å¦‚ä¸‹å†…å®¹" ä½†æ²¡æœ‰å®é™…åˆ—å‡º
        
        Args:
            content: è¦æ£€æŸ¥çš„å†…å®¹
            is_response_type: æ˜¯å¦æ˜¯å“åº”ç±»å‹æ¶ˆæ¯ï¼ˆå“åº”å¯¹é½ã€å›å¤ã€ç¡®è®¤ç­‰ï¼‰
                             å“åº”ç±»å‹å…è®¸ä»¥ç§°å‘¼å¼€å¤´ï¼Œåªè¦åç»­æœ‰å®è´¨å†…å®¹
        """
        if not content:
            return True
        
        import re
        
        # å¦‚æœå†…å®¹è¶³å¤Ÿé•¿ï¼ˆè¶…è¿‡80å­—ï¼‰ï¼Œé€šå¸¸æ˜¯å®Œæ•´çš„
        if len(content) > 80:
            return False
        
        # è¯­ä¹‰ä¸å®Œæ•´çš„æ¨¡å¼ï¼šæåˆ°äº†"ä»¥ä¸‹/å¦‚ä¸‹"ä½†å†…å®¹å¤ªçŸ­
        incomplete_indicators = [
            r'ä»¥ä¸‹[é—®é¢˜|å†…å®¹|åˆ†æ|è¦ç‚¹|å»ºè®®]',
            r'å¦‚ä¸‹[é—®é¢˜|å†…å®¹|åˆ†æ|è¦ç‚¹|å»ºè®®]',
            r'ä¸‹åˆ—[é—®é¢˜|å†…å®¹|åˆ†æ|è¦ç‚¹|å»ºè®®]',
            r'ä»¥ä¸‹æ˜¯',
            r'å¦‚ä¸‹ï¼š',
            r'åŒ…æ‹¬ï¼š$',
            r'åˆ†åˆ«æ˜¯ï¼š$',
        ]
        
        # å¦‚æœå†…å®¹å¾ˆçŸ­ï¼ˆå°‘äº50å­—ï¼‰ä¸”åŒ…å«è¿™äº›æŒ‡ç¤ºè¯ï¼Œå¯èƒ½æ˜¯ä¸å®Œæ•´çš„
        if len(content) < 50:
            for pattern in incomplete_indicators:
                if re.search(pattern, content):
                    return True
        
        # æ£€æŸ¥æ˜¯å¦åªæ˜¯ä¸€ä¸ªç§°å‘¼/é—®å€™ï¼ˆä½†è¦åŒºåˆ†å“åº”ç±»å‹ï¼‰
        # å¯¹äºå“åº”ç±»å‹ï¼Œå…è®¸ç§°å‘¼å¼€å¤´ï¼Œåªè¦åé¢æœ‰å†…å®¹
        content_stripped = content.strip()
        
        # å¦‚æœæ˜¯å“åº”ç±»å‹ï¼Œæ£€æŸ¥ç§°å‘¼åæ˜¯å¦æœ‰å®è´¨å†…å®¹
        if is_response_type:
            # æ£€æŸ¥æ˜¯å¦æ˜¯"è‡´XXX\n\nå†…å®¹"çš„æ ¼å¼
            lines = content_stripped.split('\n')
            first_line = lines[0].strip() if lines else ""
            
            # å¦‚æœç¬¬ä¸€è¡Œæ˜¯ç§°å‘¼ï¼Œæ£€æŸ¥åç»­æ˜¯å¦æœ‰å†…å®¹
            greeting_first_line = re.match(r'^(è‡´|å‘|@)[^\s\n]{2,15}[ï¼š:]?\s*$', first_line)
            if greeting_first_line:
                # æ£€æŸ¥åç»­å†…å®¹
                remaining_content = '\n'.join(lines[1:]).strip()
                # åç»­æœ‰å®è´¨å†…å®¹ï¼ˆè¶…è¿‡10å­—ç¬¦ä¸”ä¸åªæ˜¯æ ‡ç‚¹ï¼‰
                if len(remaining_content) > 10 and not re.match(r'^[\s\*\#\-\=\_\.\,\ã€‚\ï¼Œ]+$', remaining_content):
                    return False  # æœ‰å®è´¨å†…å®¹ï¼Œä¸æ˜¯ä¸å®Œæ•´çš„
                else:
                    return True  # æ²¡æœ‰å®è´¨åç»­å†…å®¹
            else:
                # ç¬¬ä¸€è¡Œä¸æ˜¯ç§°å‘¼ï¼ŒæŒ‰æ­£å¸¸é€»è¾‘å¤„ç†
                return False
        
        # éå“åº”ç±»å‹çš„ç§°å‘¼æ£€æŸ¥ï¼ˆä¸¥æ ¼æ¨¡å¼ï¼‰
        greeting_patterns = [
            r'^è‡´[^\s]{2,10}$',                    # "è‡´XXX" åªæœ‰ç§°å‘¼
            r'^å‘[^\s]{2,10}$',                    # "å‘XXX"
            r'^è¯·[^\s]{2,10}[ç¡®è®¤|æ³¨æ„|æŸ¥çœ‹]?$',   # "è¯·XXXç¡®è®¤"
            r'^@[^\s]+$',                          # "@æŸäºº"
        ]
        
        for pattern in greeting_patterns:
            if re.match(pattern, content_stripped):
                return True
        
        return False
    
    async def _check_relay_trigger(self, response: str) -> Optional[RelayMessage]:
        """æ£€æŸ¥æ˜¯å¦éœ€è¦è§¦å‘ä¸­ç»§
        
        æ™ºèƒ½æ£€æµ‹ï¼šé™¤äº†æ˜¾å¼æ ‡è®°å¤–ï¼Œä¹Ÿæ£€æµ‹å†…å®¹ä¸­çš„å…³é”®å‘ç°æ¨¡å¼
        æ”¯æŒï¼šå‘ç°ã€è¯·æ±‚ã€å“åº”ã€å»ºè®®ã€ç¡®è®¤ç­‰å¤šç§ç±»å‹
        """
        import re
        
        relay_type = None
        reason = ""
        content = ""
        target_agent_ids = []  # æ”¯æŒæŒ‡å®šç›®æ ‡
        
        # === è¾…åŠ©å‡½æ•°ï¼šæå–æ ‡è®°åçš„å®Œæ•´å†…å®¹ ===
        def extract_full_content(response: str, tag_pattern: str, tag_end: str = "]") -> tuple[str, str]:
            """
            æå–æ ‡è®°å†…å®¹ + æ ‡è®°åçš„ç›¸å…³å†…å®¹
            
            ä¾‹å¦‚ï¼š[å“åº”å¯¹é½: è‡´å½±è¯„æ•´åˆä¸“å®¶]\n\nä»¥ä¸‹æ˜¯æˆ‘çš„åˆ†æ...
            è¿”å›ï¼š("è‡´å½±è¯„æ•´åˆä¸“å®¶", "ä»¥ä¸‹æ˜¯æˆ‘çš„åˆ†æ...")
            """
            import re
            
            # æ‰¾åˆ°æ ‡è®°ä½ç½®
            tag_match = re.search(tag_pattern, response)
            if not tag_match:
                return "", ""
            
            tag_content = tag_match.group(1).strip() if tag_match.lastindex else ""
            tag_end_pos = tag_match.end()
            
            # æå–æ ‡è®°åçš„å†…å®¹ï¼ˆç›´åˆ°ä¸‹ä¸€ä¸ªæ ‡è®°æˆ–æ®µè½ç»“æŸï¼‰
            remaining = response[tag_end_pos:].strip()
            
            # æŸ¥æ‰¾åç»­å†…å®¹çš„ç»“æŸä½ç½®
            # é‡åˆ°æ–°çš„æ ‡è®°ã€åˆ†éš”çº¿ã€æˆ–è¶…è¿‡500å­—ç¬¦æ—¶åœæ­¢
            end_patterns = [
                r'\n\[',           # æ–°çš„æ ‡è®°
                r'\n---',          # åˆ†éš”çº¿
                r'\n\*\*\[',       # åŠ ç²—çš„æ ‡è®°
                r'\n##',           # æ ‡é¢˜
            ]
            
            end_pos = len(remaining)
            for end_pat in end_patterns:
                match = re.search(end_pat, remaining)
                if match and match.start() < end_pos:
                    end_pos = match.start()
            
            # é™åˆ¶é•¿åº¦
            end_pos = min(end_pos, 800)
            following_content = remaining[:end_pos].strip()
            
            return tag_content, following_content
        
        # === å“åº”ç±»æ¶ˆæ¯æ£€æµ‹ï¼ˆä¼˜å…ˆçº§æœ€é«˜ï¼‰===
        
        # æ£€æŸ¥å“åº”å¯¹é½
        if "[å“åº”å¯¹é½:" in response:
            tag_content, following = extract_full_content(response, r'\[å“åº”å¯¹é½:\s*([^\]]+)\]')
            if tag_content:
                # å“åº”å¯¹é½éœ€è¦æœ‰å®è´¨å†…å®¹
                # å¦‚æœæ ‡è®°å†…å®¹æ˜¯ç§°å‘¼å½¢å¼ï¼ˆè‡´XXXï¼‰ï¼Œå¿…é¡»æœ‰åç»­å†…å®¹
                is_greeting_format = re.match(r'^(è‡´|å‘|é’ˆå¯¹)[^\s]{2,15}', tag_content.strip())
                
                if following and len(following) > 10:
                    # æœ‰åç»­å†…å®¹ï¼Œåˆå¹¶
                    content = f"{tag_content}\n\n{following}"
                    relay_type = RelayType.ALIGNMENT_RESPONSE
                    reason = "å“åº”å¯¹é½è¯·æ±‚"
                elif not is_greeting_format and len(tag_content) > 20:
                    # ä¸æ˜¯ç§°å‘¼æ ¼å¼ï¼Œä¸”æ ‡è®°å†…å®¹æœ¬èº«å¤Ÿé•¿ï¼Œç›´æ¥ä½¿ç”¨
                    content = tag_content
                    relay_type = RelayType.ALIGNMENT_RESPONSE
                    reason = "å“åº”å¯¹é½è¯·æ±‚"
                else:
                    # æ˜¯ç§°å‘¼æ ¼å¼ä½†æ²¡æœ‰å®è´¨åç»­å†…å®¹ï¼Œè®°å½•æ—¥å¿—ä½†ä¸å‘é€
                    print(f"[SubAgent {self.agent_name}] å“åº”å¯¹é½å†…å®¹ä¸å®Œæ•´ï¼Œè·³è¿‡: tag='{tag_content[:30]}', following='{following[:30] if following else 'None'}'")
        
        # æ£€æŸ¥å›å¤
        elif "[å›å¤:" in response:
            tag_content, following = extract_full_content(response, r'\[å›å¤:\s*([^\]]+)\]')
            if tag_content:
                # åŒæ ·çš„é€»è¾‘
                is_greeting_format = re.match(r'^(è‡´|å‘|é’ˆå¯¹)[^\s]{2,15}', tag_content.strip())
                
                if following and len(following) > 10:
                    content = f"{tag_content}\n\n{following}"
                    relay_type = RelayType.ALIGNMENT_RESPONSE
                    reason = "å›å¤æ±‚åŠ©"
                elif not is_greeting_format and len(tag_content) > 20:
                    content = tag_content
                    relay_type = RelayType.ALIGNMENT_RESPONSE
                    reason = "å›å¤æ±‚åŠ©"
                else:
                    print(f"[SubAgent {self.agent_name}] å›å¤å†…å®¹ä¸å®Œæ•´ï¼Œè·³è¿‡: tag='{tag_content[:30]}', following='{following[:30] if following else 'None'}'")
        
        # æ£€æŸ¥ç¡®è®¤
        elif "[ç¡®è®¤:" in response:
            tag_content, following = extract_full_content(response, r'\[ç¡®è®¤:\s*([^\]]+)\]')
            if tag_content:
                if following and len(following) > 10:
                    content = f"{tag_content}\n\n{following}"
                else:
                    content = tag_content
                relay_type = RelayType.CONFIRMATION
                reason = "ç¡®è®¤/è®¤å¯"
        
        # === è¯·æ±‚ç±»æ¶ˆæ¯æ£€æµ‹ ===
        
        # æ£€æŸ¥æ˜¾å¼ä¸­ç»§è¯·æ±‚ï¼ˆè¯·æ±‚å¯¹é½ï¼‰
        elif "[è¯·æ±‚ä¸­ç»§:" in response:
            tag_content, following = extract_full_content(response, r'\[è¯·æ±‚ä¸­ç»§:\s*([^\]]+)\]')
            if tag_content:
                # è¯·æ±‚å¯¹é½éœ€è¦å®Œæ•´çš„ä¸Šä¸‹æ–‡
                if following and len(following) > 10:
                    content = f"è¯·æ±‚å¯¹é½: {tag_content}\n\n{following}"
                else:
                    content = f"è¯·æ±‚å¯¹é½: {tag_content}"
                relay_type = RelayType.ALIGNMENT_REQUEST
                reason = tag_content
        
        # æ£€æŸ¥ç–‘é—®/æ±‚åŠ©
        elif "[æ±‚åŠ©:" in response or "[ç–‘é—®:" in response:
            help_match = re.search(r'\[(æ±‚åŠ©|ç–‘é—®):\s*([^\]]+)\]', response)
            if help_match:
                tag_type = help_match.group(1)
                tag_content = help_match.group(2)
                # æå–åç»­å†…å®¹
                tag_end_pos = help_match.end()
                remaining = response[tag_end_pos:tag_end_pos + 500].strip()
                # ç®€å•æˆªå–åˆ°ä¸‹ä¸€ä¸ªæ ‡è®°
                next_tag = re.search(r'\n\[|\n---|\n##', remaining)
                following = remaining[:next_tag.start()].strip() if next_tag else remaining[:300].strip()
                
                if following and len(following) > 10:
                    content = f"{tag_type}: {tag_content}\n\n{following}"
                else:
                    content = f"{tag_type}: {tag_content}"
                relay_type = RelayType.QUESTION
                reason = tag_content
        
        # æ£€æŸ¥å»ºè®®
        elif "[å»ºè®®:" in response:
            tag_content, following = extract_full_content(response, r'\[å»ºè®®:\s*([^\]]+)\]')
            if tag_content:
                if following and len(following) > 10:
                    content = f"å»ºè®®: {tag_content}\n\n{following}"
                else:
                    content = f"å»ºè®®: {tag_content}"
                relay_type = RelayType.SUGGESTION
                reason = tag_content
        
        # === å‘ç°ç±»æ¶ˆæ¯æ£€æµ‹ ===
        
        # æ£€æŸ¥æ˜¾å¼å…³é”®å‘ç°æ ‡è®°
        elif "[å…³é”®å‘ç°]" in response or "**[å…³é”®å‘ç°]**" in response:
            discovery_match = re.search(r'\[å…³é”®å‘ç°\]\s*(.+?)(?:\n\n|\n-|$)', response, re.DOTALL)
            if discovery_match:
                content = discovery_match.group(1).strip()
                # éªŒè¯å†…å®¹æœ‰æ•ˆæ€§
                if len(content) >= 10 and not self._is_meaningless_content(content):
                    relay_type = RelayType.DISCOVERY
                    reason = "å‘ç°å…³é”®ä¿¡æ¯"
                else:
                    content = ""  # æ— æ•ˆå†…å®¹ï¼Œä¸å‘é€
        
        # æ£€æŸ¥æ´å¯Ÿ
        elif "[æ´å¯Ÿ]" in response or "[æ ¸å¿ƒæ´å¯Ÿ]" in response:
            insight_match = re.search(r'\[(æ ¸å¿ƒ)?æ´å¯Ÿ\]\s*(.+?)(?:\n\n|\n-|$)', response, re.DOTALL)
            if insight_match:
                content = insight_match.group(2).strip()
                # éªŒè¯å†…å®¹æœ‰æ•ˆæ€§
                if len(content) >= 10 and not self._is_meaningless_content(content):
                    relay_type = RelayType.INSIGHT
                    reason = "æ ¸å¿ƒæ´å¯Ÿ"
                else:
                    content = ""  # æ— æ•ˆå†…å®¹ï¼Œä¸å‘é€
        
        # æ–¹å¼6: æ™ºèƒ½æ£€æµ‹é‡è¦å‘ç°ï¼ˆåŸºäºå†…å®¹æ¨¡å¼ï¼‰
        # åªåœ¨è¿­ä»£è¶³å¤Ÿå¤šæ—¶å¯ç”¨ï¼Œé¿å…è¿‡æ—©è§¦å‘
        elif self.state.iterations >= 2:
            important_patterns = [
                (r'å€¼å¾—æ³¨æ„çš„æ˜¯[ï¼š:]\s*(.{20,200})', "å€¼å¾—æ³¨æ„çš„å‘ç°", RelayType.DISCOVERY),
                (r'é‡è¦å‘ç°[ï¼š:]\s*(.{20,200})', "é‡è¦å‘ç°", RelayType.DISCOVERY),
                (r'å…³é”®ç‚¹[ï¼š:]\s*(.{20,200})', "å…³é”®ç‚¹", RelayType.DISCOVERY),
                (r'æ ¸å¿ƒæ´å¯Ÿ[ï¼š:]\s*(.{20,200})', "æ ¸å¿ƒæ´å¯Ÿ", RelayType.INSIGHT),
                (r'é‡å¤§å½±å“[ï¼š:]\s*(.{20,200})', "é‡å¤§å½±å“", RelayType.DISCOVERY),
                (r'éœ€è¦å…¶ä»–.*?(?:é…åˆ|åä½œ|ç¡®è®¤)', "è·¨åŸŸåä½œéœ€æ±‚", RelayType.ALIGNMENT_REQUEST),
                (r'å»ºè®®.*?(?:è€ƒè™‘|é‡‡ç”¨|ä½¿ç”¨)', "åä½œå»ºè®®", RelayType.SUGGESTION),
            ]
            
            for pattern, pattern_reason, pattern_type in important_patterns:
                match = re.search(pattern, response)
                if match:
                    content = match.group(1) if match.lastindex else match.group(0)
                    relay_type = pattern_type
                    reason = pattern_reason
                    break
        
        # å¦‚æœæ£€æµ‹åˆ°éœ€è¦ä¸­ç»§ï¼Œå…ˆéªŒè¯å†…å®¹æœ‰æ•ˆæ€§
        if relay_type and content:
            # æ¸…ç†å†…å®¹
            content = content.strip()
            
            # åˆ¤æ–­æ˜¯å¦æ˜¯å“åº”ç±»å‹æ¶ˆæ¯ï¼ˆå“åº”å¯¹é½ã€å›å¤ã€ç¡®è®¤ç­‰ï¼‰
            is_response_type = relay_type in [
                RelayType.ALIGNMENT_RESPONSE,
                RelayType.CONFIRMATION,
            ]
            
            # éªŒè¯å†…å®¹æœ‰æ•ˆæ€§ï¼ˆæœ€å°é•¿åº¦ + éæ— æ„ä¹‰å†…å®¹ + è¯­ä¹‰å®Œæ•´æ€§ï¼‰
            if len(content) < 5:
                print(f"[SubAgent {self.agent_name}] Skipped too short relay content: '{content[:50]}...'")
                return None
            
            if self._is_meaningless_content(content):
                print(f"[SubAgent {self.agent_name}] Skipped meaningless relay content: '{content[:50]}...'")
                return None
            
            # å¯¹å“åº”ç±»å‹ä½¿ç”¨å®½æ¾çš„è¯­ä¹‰å®Œæ•´æ€§æ£€æŸ¥
            if self._is_semantically_incomplete(content, is_response_type=is_response_type):
                print(f"[SubAgent {self.agent_name}] Skipped semantically incomplete relay content: '{content[:50]}...'")
                return None
            
            relay_msg = RelayMessage(
                type=relay_type,
                source_agent_id=self.agent_id,
                source_agent_name=self.agent_name,
                target_agent_ids=target_agent_ids,  # æ”¯æŒæŒ‡å®šç›®æ ‡
                content=content[:1000],  # å¢åŠ åˆ° 1000 å­—ç¬¦ï¼Œä¿ç•™æ›´å¤šä¿¡æ¯
                importance=0.8,
                metadata={"reason": reason, "iteration": self.state.iterations}
            )
            
            self.state.relay_messages_sent.append(relay_msg.model_dump())
            
            if self.on_relay_request:
                self.on_relay_request(relay_msg)
            
            return relay_msg
        
        return None
    
    async def _process_relay_inbox(self):
        """å¤„ç†ä¸­ç»§æ”¶ä»¶ç®± - å‡çº§ç‰ˆï¼Œæ™ºèƒ½å¤„ç†äººå·¥å¹²é¢„"""
        processed_messages = []
        intervention_messages = []
        regular_messages = []
        
        # å…ˆæ”¶é›†æ‰€æœ‰æ¶ˆæ¯å¹¶åˆ†ç±»
        while not self.relay_inbox.empty():
            try:
                message: RelayMessage = self.relay_inbox.get_nowait()
                if message.type == RelayType.HUMAN_INTERVENTION:
                    intervention_messages.append(message)
                else:
                    regular_messages.append(message)
            except asyncio.QueueEmpty:
                break
        
        # ä¼˜å…ˆå¤„ç†äººå·¥å¹²é¢„æ¶ˆæ¯ï¼ˆæŒ‰é‡è¦æ€§æ’åºï¼‰
        intervention_messages.sort(key=lambda m: m.importance, reverse=True)
        
        for message in intervention_messages:
            # æ„å»ºå¢å¼ºçš„å¹²é¢„æç¤º
            intervention_content = self._build_intervention_prompt(message)
            
            self.messages.append(LLMMessage(
                role="user",
                content=intervention_content
            ))
            
            processed_messages.append(message)
        
        # å¤„ç†æ™®é€šä¸­ç»§æ¶ˆæ¯ï¼ˆæ ¹æ®ç±»å‹ç»™å‡ºä¸åŒçš„å“åº”æç¤ºï¼‰
        for message in regular_messages:
            msg_type = message.type.value if hasattr(message.type, 'value') else str(message.type)
            
            # æ ¹æ®æ¶ˆæ¯ç±»å‹æ„å»ºä¸åŒçš„å“åº”æç¤º
            if message.type == RelayType.ALIGNMENT_REQUEST:
                # å¯¹é½è¯·æ±‚ - éœ€è¦å“åº”
                prompt = f"""[æ¥è‡ª {message.source_agent_name} çš„å¯¹é½è¯·æ±‚ ğŸ”„]
å†…å®¹: {message.content}

**è¿™æ˜¯ä¸€ä¸ªéœ€è¦å“åº”çš„è¯·æ±‚ï¼** è¯·ï¼š
1. è€ƒè™‘ä½ çš„åˆ†ææ˜¯å¦ä¸æ­¤è¯·æ±‚ç›¸å…³
2. å¦‚æœç›¸å…³ï¼Œè¯·ä½¿ç”¨ä»¥ä¸‹æ ¼å¼è¿›è¡Œå“åº”ï¼š

[å“åº”å¯¹é½: é’ˆå¯¹XXXçš„å›å¤]
è¿™é‡Œå†™ä½ çš„å®é™…å“åº”å†…å®¹ï¼ŒåŒ…æ‹¬ï¼š
- ä½ çš„ç›¸å…³å‘ç°æˆ–åˆ†æç»“è®º
- å¯¹è¯·æ±‚é—®é¢˜çš„ç›´æ¥å›ç­”
- ä½ è®¤ä¸ºé‡è¦çš„è¡¥å……ä¿¡æ¯

**æ³¨æ„**ï¼šå“åº”å†…å®¹è¦å®Œæ•´å…·ä½“ï¼Œä¸è¦åªå†™ç§°å‘¼æˆ–ç©ºæ³›çš„ç¡®è®¤ã€‚
"""
            elif message.type == RelayType.QUESTION:
                # é—®é¢˜/æ±‚åŠ© - éœ€è¦å›ç­”
                prompt = f"""[æ¥è‡ª {message.source_agent_name} çš„æ±‚åŠ© â“]
å†…å®¹: {message.content}

**è¿™æ˜¯ä¸€ä¸ªæ±‚åŠ©è¯·æ±‚ï¼** å¦‚æœä½ æœ‰ç›¸å…³çŸ¥è¯†æˆ–è§è§£ï¼š
è¯·ä½¿ç”¨ä»¥ä¸‹æ ¼å¼è¿›è¡Œå›å¤ï¼š

[å›å¤: é’ˆå¯¹XXXé—®é¢˜çš„è§£ç­”]
è¿™é‡Œå†™ä½ çš„å…·ä½“å›ç­”å†…å®¹ï¼ŒåŒ…æ‹¬ï¼š
- å¯¹é—®é¢˜çš„ç›´æ¥å›ç­”
- ç›¸å…³çš„åˆ†ææˆ–ä¾æ®
- å¦‚æœ‰å¿…è¦ï¼Œé™„ä¸Šä½ çš„å»ºè®®

**æ³¨æ„**ï¼šå›å¤å†…å®¹è¦å…·ä½“æœ‰å¸®åŠ©ï¼Œä¸è¦åªå†™"å·²æ”¶åˆ°"æˆ–ç©ºæ³›ç¡®è®¤ã€‚
"""
            elif message.type == RelayType.SUGGESTION:
                # å»ºè®® - å¯é€‰é‡‡çº³
                prompt = f"""[æ¥è‡ª {message.source_agent_name} çš„å»ºè®® ğŸ’¡]
å†…å®¹: {message.content}

è¿™æ˜¯ä¸€ä¸ªå»ºè®®ï¼Œä½ å¯ä»¥ï¼š
1. å¦‚æœè®¤ä¸ºæœ‰ä»·å€¼ï¼Œæ•´åˆåˆ°ä½ çš„åˆ†æä¸­
2. ä½¿ç”¨ [ç¡®è®¤: åŸå› ] è¡¨ç¤ºé‡‡çº³
3. å¿½ç•¥å¦‚æœä¸ä½ çš„ä»»åŠ¡æ— å…³
"""
            elif message.type == RelayType.ALIGNMENT_RESPONSE:
                # å¯¹é½å“åº” - ä»…ä¾›å‚è€ƒ
                prompt = f"""[æ¥è‡ª {message.source_agent_name} çš„å¯¹é½å“åº” âœ…]
å†…å®¹: {message.content}

è¿™æ˜¯å¯¹ä¹‹å‰å¯¹é½è¯·æ±‚çš„å“åº”ï¼Œè¯·å‚è€ƒæ•´åˆã€‚
"""
            elif message.type == RelayType.CONFIRMATION:
                # ç¡®è®¤ - ä»…ä¾›å‚è€ƒ
                prompt = f"""[æ¥è‡ª {message.source_agent_name} çš„ç¡®è®¤ âœ”ï¸]
å†…å®¹: {message.content}

å…¶ä»– Agent ç¡®è®¤äº†ä½ çš„å‘ç°/å»ºè®®ã€‚
"""
            elif message.type == RelayType.INSIGHT:
                # æ´å¯Ÿ - é«˜ä»·å€¼ä¿¡æ¯
                prompt = f"""[æ¥è‡ª {message.source_agent_name} çš„æ ¸å¿ƒæ´å¯Ÿ ğŸ¯]
å†…å®¹: {message.content}

è¿™æ˜¯ä¸€ä¸ªé‡è¦çš„æ´å¯Ÿï¼Œè¯·ä»”ç»†è€ƒè™‘æ˜¯å¦èƒ½æ•´åˆåˆ°ä½ çš„åˆ†æä¸­ã€‚
"""
            else:
                # é»˜è®¤å¤„ç†ï¼ˆdiscovery ç­‰ï¼‰
                prompt = f"""[æ¥è‡ª {message.source_agent_name} çš„ä¸­ç»§æ¶ˆæ¯]
ç±»å‹: {msg_type}
å†…å®¹: {message.content}

è¯·è€ƒè™‘è¿™ä¸ªä¿¡æ¯ï¼Œå¦‚æœå®ƒä¸ä½ çš„åˆ†æç›¸å…³ï¼Œè¯·è¿›è¡Œæ•´åˆå’Œè°ƒæ•´ã€‚
"""
            
            self.messages.append(LLMMessage(
                role="user",
                content=prompt
            ))
            processed_messages.append(message)
        
        return processed_messages
    
    def _build_intervention_prompt(self, message: RelayMessage) -> str:
        """æ„å»ºäººå·¥å¹²é¢„çš„æ™ºèƒ½æç¤º
        
        æ ¹æ®å¹²é¢„ç±»å‹å’Œå†…å®¹ï¼Œæ„å»ºå¼•å¯¼ Agent æ­£ç¡®å“åº”çš„æç¤º
        """
        intervention_type = message.metadata.get("intervention_type", "unknown")
        priority = message.metadata.get("priority", 5)
        payload = message.metadata.get("payload", {})
        
        # åŸºç¡€æ¡†æ¶
        prompt_parts = [
            f"âš ï¸ **[é‡è¦ï¼šäººå·¥å¹²é¢„é€šçŸ¥ - ä¼˜å…ˆçº§ {priority}/10]**",
            f"",
            f"æ¥è‡ª: {message.source_agent_name}",
            f"",
        ]
        
        # æ ¹æ®å¹²é¢„ç±»å‹æ·»åŠ å…·ä½“æŒ‡å¯¼
        if intervention_type == InterventionType.INJECT.value:
            info = payload.get("information", message.content)
            prompt_parts.extend([
                "**ç±»å‹**: ä¿¡æ¯æ³¨å…¥",
                "",
                "**æ³¨å…¥å†…å®¹**:",
                info,
                "",
                "**è¯·æ‰§è¡Œä»¥ä¸‹æ“ä½œ**:",
                "1. ä»”ç»†é˜…è¯»ä¸Šè¿°æ³¨å…¥çš„ä¿¡æ¯",
                "2. è¯„ä¼°è¿™äº›ä¿¡æ¯ä¸ä½ å½“å‰ä»»åŠ¡çš„ç›¸å…³æ€§",
                "3. å¦‚æœç›¸å…³ï¼Œå°†å…¶æ•´åˆåˆ°ä½ çš„åˆ†æä¸­",
                "4. å¦‚æœéœ€è¦è°ƒæ•´æ–¹å‘ï¼Œè¯´æ˜è°ƒæ•´åŸå› ",
                "5. åœ¨ä¸‹ä¸€è½®è¾“å‡ºä¸­ä½“ç°å¯¹è¿™äº›ä¿¡æ¯çš„è€ƒè™‘",
            ])
        
        elif intervention_type == InterventionType.ADJUST.value:
            adjustments = payload.get("adjustments", {})
            prompt_parts.extend([
                "**ç±»å‹**: è¡Œä¸ºè°ƒæ•´æŒ‡ä»¤",
                "",
                "**è°ƒæ•´è¦æ±‚**:",
            ])
            for key, value in adjustments.items():
                prompt_parts.append(f"- {key}: {value}")
            prompt_parts.extend([
                "",
                "**è¯·æ‰§è¡Œä»¥ä¸‹æ“ä½œ**:",
                "1. ç†è§£ä¸Šè¿°è°ƒæ•´è¦æ±‚",
                "2. è¯„ä¼°å¦‚ä½•åœ¨ä¿æŒä»»åŠ¡ç›®æ ‡çš„å‰æä¸‹èå…¥è¿™äº›è°ƒæ•´",
                "3. åœ¨åç»­å·¥ä½œä¸­ä½“ç°è¿™äº›è°ƒæ•´",
                "4. å¦‚æœæŸäº›è°ƒæ•´ä¸å½“å‰ä»»åŠ¡å†²çªï¼Œè¯·è¯´æ˜åŸå› ",
            ])
        
        elif intervention_type == InterventionType.PAUSE.value:
            prompt_parts.extend([
                "**ç±»å‹**: æš‚åœé€šçŸ¥",
                "",
                message.content,
                "",
                "**æ³¨æ„**: ä½ å¯èƒ½å³å°†è¢«æš‚åœï¼Œè¯·åœ¨å½“å‰å“åº”ä¸­æ€»ç»“è¿›åº¦ã€‚",
            ])
        
        elif intervention_type == InterventionType.RESUME.value:
            prompt_parts.extend([
                "**ç±»å‹**: æ¢å¤é€šçŸ¥",
                "",
                message.content,
                "",
                "**è¯·æ‰§è¡Œä»¥ä¸‹æ“ä½œ**:",
                "1. å›é¡¾ä¹‹å‰çš„å·¥ä½œè¿›åº¦",
                "2. ç»§ç»­æœªå®Œæˆçš„ä»»åŠ¡",
                "3. å¦‚æœ‰æ–°çš„ä¿¡æ¯éœ€è¦è€ƒè™‘ï¼Œè¯·æ•´åˆè¿›æ¥",
            ])
        
        elif intervention_type == InterventionType.CANCEL.value:
            prompt_parts.extend([
                "**ç±»å‹**: å–æ¶ˆé€šçŸ¥",
                "",
                message.content,
                "",
                "**æ³¨æ„**: å¦ä¸€ä¸ª Agent çš„ä»»åŠ¡å·²è¢«å–æ¶ˆã€‚å¦‚æœè¿™å½±å“åˆ°ä½ çš„å·¥ä½œï¼Œè¯·ç›¸åº”è°ƒæ•´ã€‚",
            ])
        
        else:
            # é€šç”¨å¤„ç†
            prompt_parts.extend([
                message.content,
                "",
                "è¯·æ ¹æ®ä¸Šè¿°äººå·¥å¹²é¢„ä¿¡æ¯ï¼Œé€‚å½“è°ƒæ•´ä½ çš„å·¥ä½œã€‚",
            ])
        
        # æ·»åŠ ç¡®è®¤è¦æ±‚
        if message.metadata.get("requires_acknowledgement"):
            prompt_parts.extend([
                "",
                "---",
                "ğŸ“ è¯·åœ¨ä½ çš„ä¸‹ä¸€è½®å“åº”å¼€å¤´ç¡®è®¤æ”¶åˆ°æ­¤å¹²é¢„é€šçŸ¥ã€‚",
            ])
        
        return "\n".join(prompt_parts)
    
    def _build_continuation_prompt(
        self, 
        iteration: int, 
        last_response: str,
        pending_summary: Optional[Dict[str, Any]] = None
    ) -> str:
        """æ„å»ºç»§ç»­è¿­ä»£çš„å¼•å¯¼æç¤º
        
        æ ¹æ®å½“å‰è¿­ä»£é˜¶æ®µã€ä¸Šä¸€è½®è¾“å‡ºå’Œå¾…å¤„ç†æ¶ˆæ¯ï¼Œå¼•å¯¼ Agent ç»§ç»­æ·±å…¥åˆ†æ
        
        Args:
            iteration: å½“å‰è¿­ä»£æ¬¡æ•°
            last_response: ä¸Šä¸€è½®å“åº”
            pending_summary: å¾…å¤„ç†æ¶ˆæ¯æ‘˜è¦ï¼ˆå¦‚æœæœ‰ï¼‰
        """
        prompt_parts = []
        
        # å¦‚æœæœ‰å¾…å¤„ç†æ¶ˆæ¯ï¼Œä¼˜å…ˆæé†’
        if pending_summary and pending_summary.get("total_count", 0) > 0:
            prompt_parts.append("âš ï¸ **æ³¨æ„ï¼šä¸­ç»§ç«™æœ‰å¾…å¤„ç†çš„æ¶ˆæ¯**")
            prompt_parts.append("")
            
            if pending_summary.get("intervention_count", 0) > 0:
                prompt_parts.append(f"- äººå·¥å¹²é¢„æ¶ˆæ¯: {pending_summary['intervention_count']} æ¡")
                for intervention in pending_summary.get("interventions", []):
                    prompt_parts.append(f"  - ç±»å‹: {intervention['type']}, ä¼˜å…ˆçº§: {intervention['priority']}")
            
            if pending_summary.get("total_count", 0) > pending_summary.get("intervention_count", 0):
                other_count = pending_summary["total_count"] - pending_summary.get("intervention_count", 0)
                prompt_parts.append(f"- å…¶ä»–ä¸­ç»§æ¶ˆæ¯: {other_count} æ¡")
            
            prompt_parts.append("")
            prompt_parts.append("è¯·å…ˆå¤„ç†è¿™äº›æ¶ˆæ¯åå†ç»§ç»­ä½ çš„åˆ†æã€‚")
            prompt_parts.append("")
            prompt_parts.append("---")
            prompt_parts.append("")
        
        # æ ¹æ®è¿­ä»£é˜¶æ®µæ·»åŠ å¼•å¯¼
        if iteration == 1:
            # ç¬¬ä¸€è½®åï¼Œå¼•å¯¼æ·±å…¥ç»†èŠ‚
            prompt_parts.extend([
                "ä½ çš„åˆæ­¥åˆ†æå¾ˆå¥½ã€‚ç°åœ¨è¯·ï¼š",
                "1. é’ˆå¯¹ä½ æåˆ°çš„å…³é”®ç‚¹ï¼Œè¿›è¡Œæ›´æ·±å…¥çš„åˆ†æ",
                "2. è€ƒè™‘æ˜¯å¦æœ‰é—æ¼çš„è§’åº¦æˆ–ç»´åº¦",
                "3. å¦‚æœæœ‰é‡è¦å‘ç°ï¼Œè¯·ç”¨ **[å…³é”®å‘ç°]** æ ‡è®°",
                "",
                "ç»§ç»­æ·±å…¥åˆ†æï¼š"
            ])
        elif iteration == 2:
            # ç¬¬äºŒè½®åï¼Œå¼•å¯¼å‘ç°å…³è”
            prompt_parts.extend([
                "åˆ†ææ­£åœ¨æ·±å…¥ã€‚è¯·ï¼š",
                "1. æ€è€ƒä½ çš„å‘ç°ä¹‹é—´æœ‰ä»€ä¹ˆå…³è”æˆ–æ¨¡å¼",
                "2. æ˜¯å¦æœ‰éœ€è¦ä¸å…¶ä»–ä¸“å®¶è§’è‰²åä½œç¡®è®¤çš„é—®é¢˜ï¼Ÿå¦‚æœ‰ï¼Œè¯·ç”¨ **[è¯·æ±‚ä¸­ç»§: åŸå› ]** æ ‡è®°",
                "3. ç»§ç»­æŒ–æ˜æ½œåœ¨çš„æ´å¯Ÿ",
                "",
                "ç»§ç»­åˆ†æï¼š"
            ])
        elif iteration == 3:
            # ç¬¬ä¸‰è½®åï¼Œå¼•å¯¼æ•´åˆ
            prompt_parts.extend([
                "åˆ†æå·²ç»æ¯”è¾ƒæ·±å…¥ã€‚è¯·ï¼š",
                "1. å°è¯•æ•´åˆä½ çš„å„é¡¹å‘ç°",
                "2. å½¢æˆåˆæ­¥çš„ç»“è®ºæ¡†æ¶",
                "3. å¦‚æœä½ è®¤ä¸ºåˆ†æå·²ç»å®Œæ•´ï¼Œå¯ä»¥ç”¨ **[ä»»åŠ¡å®Œæˆ]** æ ‡è®°å¹¶ç»™å‡ºå®Œæ•´ç»“è®º",
                "",
                "ç»§ç»­ï¼š"
            ])
        else:
            # åç»­è½®æ¬¡ï¼Œç»™äºˆæ›´å¤§è‡ªç”±åº¦
            prompt_parts.extend([
                "è¯·ç»§ç»­ä½ çš„åˆ†æï¼Œå¦‚æœä½ è®¤ä¸ºå·²ç»è¶³å¤Ÿæ·±å…¥å’Œå®Œæ•´ï¼Œè¯·ç”¨ **[ä»»åŠ¡å®Œæˆ]** æ ‡è®°å¹¶ç»™å‡ºæœ€ç»ˆåˆ†æç»“æœã€‚",
                "",
                "ç»§ç»­ï¼š"
            ])
        
        return "\n".join(prompt_parts)
    
    def _build_pending_message_prompt(self, pending_summary: Dict[str, Any]) -> str:
        """æ„å»ºå¾…å¤„ç†æ¶ˆæ¯æç¤º
        
        å½“ Agent å°è¯•å®Œæˆä»»åŠ¡ä½†æœ‰æœªå¤„ç†çš„ä¸­ç»§æ¶ˆæ¯æ—¶ï¼Œ
        å¼•å¯¼å…¶å…ˆå¤„ç†è¿™äº›æ¶ˆæ¯
        
        Args:
            pending_summary: å¾…å¤„ç†æ¶ˆæ¯æ‘˜è¦
        """
        prompt_parts = [
            "âš ï¸ **ä»»åŠ¡å®Œæˆè¢«é˜»æ­¢**",
            "",
            "åœ¨æ ‡è®°ä»»åŠ¡å®Œæˆä¹‹å‰ï¼Œä½ éœ€è¦å…ˆå¤„ç†ä¸­ç»§ç«™ä¸­çš„å¾…å¤„ç†æ¶ˆæ¯ï¼š",
            "",
        ]
        
        # è¯¦ç»†åˆ—å‡ºå¾…å¤„ç†å†…å®¹
        if pending_summary.get("intervention_count", 0) > 0:
            prompt_parts.append(f"ğŸ“¢ **äººå·¥å¹²é¢„æ¶ˆæ¯** ({pending_summary['intervention_count']} æ¡):")
            for i, intervention in enumerate(pending_summary.get("interventions", []), 1):
                prompt_parts.append(f"  {i}. ç±»å‹: {intervention['type']}")
                prompt_parts.append(f"     ä¼˜å…ˆçº§: {intervention['priority']}/10")
                prompt_parts.append(f"     å†…å®¹é¢„è§ˆ: {intervention['content_preview'][:80]}...")
            prompt_parts.append("")
        
        if pending_summary.get("unacknowledged_count", 0) > 0:
            prompt_parts.append(f"â— **æœªç¡®è®¤çš„å¹²é¢„æ¶ˆæ¯**: {pending_summary['unacknowledged_count']} æ¡")
            prompt_parts.append("")
        
        other_count = pending_summary.get("total_count", 0) - pending_summary.get("intervention_count", 0)
        if other_count > 0:
            prompt_parts.append(f"ğŸ’¬ **å…¶ä»–ä¸­ç»§æ¶ˆæ¯**: {other_count} æ¡")
            prompt_parts.append("")
        
        # æ·»åŠ å¤„ç†æŒ‡å¯¼
        prompt_parts.extend([
            "---",
            "",
            "**è¯·æŒ‰ä»¥ä¸‹æ­¥éª¤å¤„ç†**ï¼š",
            "1. ä»”ç»†é˜…è¯»ä¸Šè¿°å¾…å¤„ç†æ¶ˆæ¯çš„å†…å®¹",
            "2. æ ¹æ®æ¶ˆæ¯å†…å®¹è°ƒæ•´ä½ çš„åˆ†ææˆ–ç»“è®º",
            "3. å¦‚æœæ”¶åˆ°äººå·¥å¹²é¢„ï¼Œè¯·æ˜ç¡®ç¡®è®¤ï¼šã€Œå·²æ”¶åˆ°å¹²é¢„é€šçŸ¥ï¼Œå†…å®¹æ˜¯...ã€",
            "4. å¦‚æœå¹²é¢„è¦æ±‚ä½ è°ƒæ•´æ–¹å‘ï¼Œè¯·è¯´æ˜ä½ çš„è°ƒæ•´",
            "5. å¤„ç†å®Œæ‰€æœ‰æ¶ˆæ¯åï¼Œå†è€ƒè™‘æ˜¯å¦å¯ä»¥å®Œæˆä»»åŠ¡",
            "",
            "è¯·å¤„ç†è¿™äº›æ¶ˆæ¯å¹¶ç»™å‡ºä½ çš„å“åº”ï¼š"
        ])
        
        return "\n".join(prompt_parts)
    
    def _update_status(self, status: AgentStatus):
        """æ›´æ–°çŠ¶æ€"""
        self.state.status = status
        self.state.updated_at = datetime.now()
    
    def _update_progress(self, progress: float, step: str):
        """æ›´æ–°è¿›åº¦"""
        self.state.progress = progress
        self.state.current_step = step
        self.state.updated_at = datetime.now()
        
        if self.on_progress:
            self.on_progress(self.agent_id, progress, step)
